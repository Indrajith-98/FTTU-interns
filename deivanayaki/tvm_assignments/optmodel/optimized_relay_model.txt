def @main(%inputs: Tensor[(1, 32, 32, 3), float32] /* ty=Tensor[(1, 32, 32, 3), float32] span=StatefulPartitionedCall/sequential_1/conv2d_1/convolution__6.inputs:0:0 */) -> Tensor[(1, 10), float32] {
  %43 = fn (%p013: Tensor[(1, 32, 32, 3), float32] /* ty=Tensor[(1, 32, 32, 3), float32] */, Primitive=1) -> Tensor[(1, 3, 32, 32), float32] {
    transpose(%p013, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 3, 32, 32), float32] span=StatefulPartitionedCall/sequential_1/conv2d_1/convolution__6:0:0 */
  } /* ty=fn (Tensor[(1, 32, 32, 3), float32]) -> Tensor[(1, 3, 32, 32), float32] */;
  %44 = %43(%inputs) /* ty=Tensor[(1, 3, 32, 32), float32] */;
  %45 = fn (%p012: Tensor[(1, 3, 32, 32), float32] /* ty=Tensor[(1, 3, 32, 32), float32] */, %p17: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %p27: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, Primitive=1) -> Tensor[(1, 64, 30, 30), float32] {
    %42 = nn.conv2d(%p012, %p17, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 30, 30), float32] span=Conv__31:0:0 */;
    nn.bias_add(%42, %p27) /* ty=Tensor[(1, 64, 30, 30), float32] span=Conv__31:0:0 */
  } /* ty=fn (Tensor[(1, 3, 32, 32), float32], Tensor[(64, 3, 3, 3), float32], Tensor[(64), float32]) -> Tensor[(1, 64, 30, 30), float32] */;
  %46 = %45(%44, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 3, 3), float32] span=Conv__31.StatefulPartitionedCall/sequential_1/conv2d_1/convolution/ReadVariableOp:0:0:0 */, meta[relay.Constant][1] /* ty=Tensor[(64), float32] span=Conv__31.StatefulPartitionedCall/sequential_1/conv2d_1/Reshape:0:0:0 */) /* ty=Tensor[(1, 64, 30, 30), float32] */;
  %47 = fn (%p011: Tensor[(1, 64, 30, 30), float32] /* ty=Tensor[(1, 64, 30, 30), float32] */, %p16: Tensor[(30, 30, 64), float32] /* ty=Tensor[(30, 30, 64), float32] */, %p26: Tensor[(1, 64, 1, 1), float32] /* ty=Tensor[(1, 64, 1, 1), float32] */, %p33: Tensor[(1, 64, 1, 1), float32] /* ty=Tensor[(1, 64, 1, 1), float32] */, Primitive=1) -> Tensor[(1, 64, 30, 30), float32] {
    %34 = negative(%p011) /* ty=Tensor[(1, 64, 30, 30), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1/Neg_1:0:0 */;
    %35 = nn.relu(%34) /* ty=Tensor[(1, 64, 30, 30), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1/Relu_1:0:0 */;
    %36 = transpose(%35, axes=[0, 2, 3, 1]) /* ty=Tensor[(1, 30, 30, 64), float32] span=Transpose__33:0:0 */;
    %37 = multiply(%36, %p16) /* ty=Tensor[(1, 30, 30, 64), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1/mul:0:0 */;
    %38 = nn.relu(%p011) /* ty=Tensor[(1, 64, 30, 30), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1/Relu:0:0 */;
    %39 = transpose(%37, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 64, 30, 30), float32] span=Transpose__49:0:0 */;
    %40 = add(%38, %39) /* ty=Tensor[(1, 64, 30, 30), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1/add:0:0 */;
    %41 = multiply(%40, %p26) /* ty=Tensor[(1, 64, 30, 30), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_1/batchnorm/mul_1:0:0 */;
    add(%41, %p33) /* ty=Tensor[(1, 64, 30, 30), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_1/batchnorm/add_1:0:0 */
  } /* ty=fn (Tensor[(1, 64, 30, 30), float32], Tensor[(30, 30, 64), float32], Tensor[(1, 64, 1, 1), float32], Tensor[(1, 64, 1, 1), float32]) -> Tensor[(1, 64, 30, 30), float32] */;
  %48 = %47(%46, meta[relay.Constant][2] /* ty=Tensor[(30, 30, 64), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1/mul.StatefulPartitionedCall/sequential_1/p_re_lu_1/Neg:0:0:0 */, meta[relay.Constant][3] /* ty=Tensor[(1, 64, 1, 1), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_1/batchnorm/mul_1.StatefulPartitionedCall/sequential_1/batch_normalization_1/batchnorm/mul:0:0:0 */, meta[relay.Constant][4] /* ty=Tensor[(1, 64, 1, 1), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_1/batchnorm/add_1.const_fold_opt__90:0:0 */) /* ty=Tensor[(1, 64, 30, 30), float32] */;
  %49 = fn (%p010: Tensor[(1, 64, 30, 30), float32] /* ty=Tensor[(1, 64, 30, 30), float32] */, Primitive=1) -> Tensor[(1, 64, 15, 15), float32] {
    nn.max_pool2d(%p010, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 15, 15), float32] span=StatefulPartitionedCall/sequential_1/max_pooling2d_1/MaxPool2d:0:0 */
  } /* ty=fn (Tensor[(1, 64, 30, 30), float32]) -> Tensor[(1, 64, 15, 15), float32] */;
  %50 = %49(%48) /* ty=Tensor[(1, 64, 15, 15), float32] */;
  %51 = fn (%p09: Tensor[(1, 64, 15, 15), float32] /* ty=Tensor[(1, 64, 15, 15), float32] */, %p15: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %p25: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1) -> Tensor[(1, 128, 13, 13), float32] {
    %33 = nn.conv2d(%p09, %p15, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 13, 13), float32] span=Conv__37:0:0 */;
    nn.bias_add(%33, %p25) /* ty=Tensor[(1, 128, 13, 13), float32] span=Conv__37:0:0 */
  } /* ty=fn (Tensor[(1, 64, 15, 15), float32], Tensor[(128, 64, 3, 3), float32], Tensor[(128), float32]) -> Tensor[(1, 128, 13, 13), float32] */;
  %52 = %51(%50, meta[relay.Constant][5] /* ty=Tensor[(128, 64, 3, 3), float32] span=Conv__37.StatefulPartitionedCall/sequential_1/conv2d_1_2/convolution/ReadVariableOp:0:0:0 */, meta[relay.Constant][6] /* ty=Tensor[(128), float32] span=Conv__37.StatefulPartitionedCall/sequential_1/conv2d_1_2/Reshape:0:0:0 */) /* ty=Tensor[(1, 128, 13, 13), float32] */;
  %53 = fn (%p08: Tensor[(1, 128, 13, 13), float32] /* ty=Tensor[(1, 128, 13, 13), float32] */, %p14: Tensor[(13, 13, 128), float32] /* ty=Tensor[(13, 13, 128), float32] */, %p24: Tensor[(1, 128, 1, 1), float32] /* ty=Tensor[(1, 128, 1, 1), float32] */, %p32: Tensor[(1, 128, 1, 1), float32] /* ty=Tensor[(1, 128, 1, 1), float32] */, Primitive=1) -> Tensor[(1, 128, 13, 13), float32] {
    %25 = negative(%p08) /* ty=Tensor[(1, 128, 13, 13), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1_2/Neg_1:0:0 */;
    %26 = nn.relu(%25) /* ty=Tensor[(1, 128, 13, 13), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1_2/Relu_1:0:0 */;
    %27 = transpose(%26, axes=[0, 2, 3, 1]) /* ty=Tensor[(1, 13, 13, 128), float32] span=Transpose__41:0:0 */;
    %28 = multiply(%27, %p14) /* ty=Tensor[(1, 13, 13, 128), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1_2/mul:0:0 */;
    %29 = nn.relu(%p08) /* ty=Tensor[(1, 128, 13, 13), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1_2/Relu:0:0 */;
    %30 = transpose(%28, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 128, 13, 13), float32] span=Transpose__57:0:0 */;
    %31 = add(%29, %30) /* ty=Tensor[(1, 128, 13, 13), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1_2/add:0:0 */;
    %32 = multiply(%31, %p24) /* ty=Tensor[(1, 128, 13, 13), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_1_2/batchnorm/mul_1:0:0 */;
    add(%32, %p32) /* ty=Tensor[(1, 128, 13, 13), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_1_2/batchnorm/add_1:0:0 */
  } /* ty=fn (Tensor[(1, 128, 13, 13), float32], Tensor[(13, 13, 128), float32], Tensor[(1, 128, 1, 1), float32], Tensor[(1, 128, 1, 1), float32]) -> Tensor[(1, 128, 13, 13), float32] */;
  %54 = %53(%52, meta[relay.Constant][7] /* ty=Tensor[(13, 13, 128), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_1_2/mul.StatefulPartitionedCall/sequential_1/p_re_lu_1_2/Neg:0:0:0 */, meta[relay.Constant][8] /* ty=Tensor[(1, 128, 1, 1), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_1_2/batchnorm/mul_1.StatefulPartitionedCall/sequential_1/batch_normalization_1_2/batchnorm/mul:0:0:0 */, meta[relay.Constant][9] /* ty=Tensor[(1, 128, 1, 1), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_1_2/batchnorm/add_1.const_fold_opt__93:0:0 */) /* ty=Tensor[(1, 128, 13, 13), float32] */;
  %55 = fn (%p07: Tensor[(1, 128, 13, 13), float32] /* ty=Tensor[(1, 128, 13, 13), float32] */, Primitive=1) -> Tensor[(1, 128, 6, 6), float32] {
    nn.max_pool2d(%p07, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 6, 6), float32] span=StatefulPartitionedCall/sequential_1/max_pooling2d_1_2/MaxPool2d:0:0 */
  } /* ty=fn (Tensor[(1, 128, 13, 13), float32]) -> Tensor[(1, 128, 6, 6), float32] */;
  %56 = %55(%54) /* ty=Tensor[(1, 128, 6, 6), float32] */;
  %57 = fn (%p06: Tensor[(1, 128, 6, 6), float32] /* ty=Tensor[(1, 128, 6, 6), float32] */, %p13: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] */, %p23: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1) -> Tensor[(1, 128, 4, 4), float32] {
    %24 = nn.conv2d(%p06, %p13, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 4, 4), float32] span=Conv__43:0:0 */;
    nn.bias_add(%24, %p23) /* ty=Tensor[(1, 128, 4, 4), float32] span=Conv__43:0:0 */
  } /* ty=fn (Tensor[(1, 128, 6, 6), float32], Tensor[(128, 128, 3, 3), float32], Tensor[(128), float32]) -> Tensor[(1, 128, 4, 4), float32] */;
  %58 = %57(%56, meta[relay.Constant][10] /* ty=Tensor[(128, 128, 3, 3), float32] span=Conv__43.StatefulPartitionedCall/sequential_1/conv2d_2_1/convolution/ReadVariableOp:0:0:0 */, meta[relay.Constant][11] /* ty=Tensor[(128), float32] span=Conv__43.StatefulPartitionedCall/sequential_1/conv2d_2_1/Reshape:0:0:0 */) /* ty=Tensor[(1, 128, 4, 4), float32] */;
  %59 = fn (%p05: Tensor[(1, 128, 4, 4), float32] /* ty=Tensor[(1, 128, 4, 4), float32] */, %p12: Tensor[(4, 4, 128), float32] /* ty=Tensor[(4, 4, 128), float32] */, %p22: Tensor[(1, 128, 1, 1), float32] /* ty=Tensor[(1, 128, 1, 1), float32] */, %p31: Tensor[(1, 128, 1, 1), float32] /* ty=Tensor[(1, 128, 1, 1), float32] */, Primitive=1) -> Tensor[(1, 128, 4, 4), float32] {
    %16 = negative(%p05) /* ty=Tensor[(1, 128, 4, 4), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_2_1/Neg_1:0:0 */;
    %17 = nn.relu(%16) /* ty=Tensor[(1, 128, 4, 4), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_2_1/Relu_1:0:0 */;
    %18 = transpose(%17, axes=[0, 2, 3, 1]) /* ty=Tensor[(1, 4, 4, 128), float32] span=Transpose__47:0:0 */;
    %19 = multiply(%18, %p12) /* ty=Tensor[(1, 4, 4, 128), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_2_1/mul:0:0 */;
    %20 = nn.relu(%p05) /* ty=Tensor[(1, 128, 4, 4), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_2_1/Relu:0:0 */;
    %21 = transpose(%19, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 128, 4, 4), float32] span=Transpose__65:0:0 */;
    %22 = add(%20, %21) /* ty=Tensor[(1, 128, 4, 4), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_2_1/add:0:0 */;
    %23 = multiply(%22, %p22) /* ty=Tensor[(1, 128, 4, 4), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_2_1/batchnorm/mul_1:0:0 */;
    add(%23, %p31) /* ty=Tensor[(1, 128, 4, 4), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_2_1/batchnorm/add_1:0:0 */
  } /* ty=fn (Tensor[(1, 128, 4, 4), float32], Tensor[(4, 4, 128), float32], Tensor[(1, 128, 1, 1), float32], Tensor[(1, 128, 1, 1), float32]) -> Tensor[(1, 128, 4, 4), float32] */;
  %60 = %59(%58, meta[relay.Constant][12] /* ty=Tensor[(4, 4, 128), float32] span=StatefulPartitionedCall/sequential_1/p_re_lu_2_1/mul.StatefulPartitionedCall/sequential_1/p_re_lu_2_1/Neg:0:0:0 */, meta[relay.Constant][13] /* ty=Tensor[(1, 128, 1, 1), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_2_1/batchnorm/mul_1.StatefulPartitionedCall/sequential_1/batch_normalization_2_1/batchnorm/mul:0:0:0 */, meta[relay.Constant][14] /* ty=Tensor[(1, 128, 1, 1), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_2_1/batchnorm/add_1.const_fold_opt__91:0:0 */) /* ty=Tensor[(1, 128, 4, 4), float32] */;
  %61 = fn (%p04: Tensor[(1, 128, 4, 4), float32] /* ty=Tensor[(1, 128, 4, 4), float32] */, Primitive=1) -> Tensor[(1, 128, 2, 2), float32] {
    nn.max_pool2d(%p04, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 2, 2), float32] span=StatefulPartitionedCall/sequential_1/max_pooling2d_2_1/MaxPool2d:0:0 */
  } /* ty=fn (Tensor[(1, 128, 4, 4), float32]) -> Tensor[(1, 128, 2, 2), float32] */;
  %62 = %61(%60) /* ty=Tensor[(1, 128, 2, 2), float32] */;
  %63 = fn (%p03: Tensor[(1, 128, 2, 2), float32] /* ty=Tensor[(1, 128, 2, 2), float32] */, Primitive=1) -> Tensor[(1, 512), float32] {
    %15 = transpose(%p03, axes=[0, 2, 3, 1]) /* ty=Tensor[(1, 2, 2, 128), float32] span=StatefulPartitionedCall/sequential_1/max_pooling2d_2_1/MaxPool2d__28:0:0 */;
    reshape(%15, newshape=[-1, 512]) /* ty=Tensor[(1, 512), float32] span=StatefulPartitionedCall/sequential_1/flatten_1/Reshape:0:0 */
  } /* ty=fn (Tensor[(1, 128, 2, 2), float32]) -> Tensor[(1, 512), float32] */;
  %64 = %63(%62) /* ty=Tensor[(1, 512), float32] */;
  %65 = fn (%p02: Tensor[(1, 512), float32] /* ty=Tensor[(1, 512), float32] */, %p11: Tensor[(256, 512), float32] /* ty=Tensor[(256, 512), float32] */, %p21: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %p3: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %p4: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, Primitive=1) -> Tensor[(1, 256), float32] {
    %2 = nn.dense(%p02, %p11, units=None, out_dtype="float32") /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/MatMul:0:0 */;
    %3 = expand_dims(%p21, axis=0) /* ty=Tensor[(1, 256), float32] */;
    %4 = add(%2, %3) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/Add:0:0 */;
    %5 = exp(%4) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */;
    %6 = subtract(1f /* ty=float32 span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */, %5) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */;
    %7 = nn.relu(%6) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */;
    %8 = multiply(-1.67326f /* ty=float32 span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */, %7) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */;
    %9 = nn.relu(%4) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */;
    %10 = add(%8, %9) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */;
    %11 = multiply(1.0507f /* ty=float32 span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */, %10) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/Selu:0:0 */;
    %12 = expand_dims(%p3, axis=0) /* ty=Tensor[(1, 256), float32] */;
    %13 = multiply(%11, %12) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_3_1/batchnorm/mul_1:0:0 */;
    %14 = expand_dims(%p4, axis=0) /* ty=Tensor[(1, 256), float32] */;
    add(%13, %14) /* ty=Tensor[(1, 256), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_3_1/batchnorm/add_1:0:0 */
  } /* ty=fn (Tensor[(1, 512), float32], Tensor[(256, 512), float32], Tensor[(256), float32], Tensor[(256), float32], Tensor[(256), float32]) -> Tensor[(1, 256), float32] */;
  %66 = %65(%64, meta[relay.Constant][15] /* ty=Tensor[(256, 512), float32] span=StatefulPartitionedCall/sequential_1/dense_1/MatMul:0:0 */, meta[relay.Constant][16] /* ty=Tensor[(256), float32] span=StatefulPartitionedCall/sequential_1/dense_1/Add.StatefulPartitionedCall/sequential_1/dense_1/Add/ReadVariableOp:0:0:0 */, meta[relay.Constant][17] /* ty=Tensor[(256), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_3_1/batchnorm/mul_1.StatefulPartitionedCall/sequential_1/batch_normalization_3_1/batchnorm/mul:0:0:0 */, meta[relay.Constant][18] /* ty=Tensor[(256), float32] span=StatefulPartitionedCall/sequential_1/batch_normalization_3_1/batchnorm/add_1.StatefulPartitionedCall/sequential_1/batch_normalization_3_1/batchnorm/sub:0:0:0 */) /* ty=Tensor[(1, 256), float32] */;
  %67 = fn (%p01: Tensor[(1, 256), float32] /* ty=Tensor[(1, 256), float32] */, %p1: Tensor[(10, 256), float32] /* ty=Tensor[(10, 256), float32] */, %p2: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1) -> Tensor[(1, 10), float32] {
    %0 = nn.dense(%p01, %p1, units=None, out_dtype="float32") /* ty=Tensor[(1, 10), float32] span=StatefulPartitionedCall/sequential_1/dense_1_2/MatMul:0:0 */;
    %1 = expand_dims(%p2, axis=0) /* ty=Tensor[(1, 10), float32] */;
    add(%0, %1) /* ty=Tensor[(1, 10), float32] span=StatefulPartitionedCall/sequential_1/dense_1_2/Add:0:0 */
  } /* ty=fn (Tensor[(1, 256), float32], Tensor[(10, 256), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %68 = %67(%66, meta[relay.Constant][19] /* ty=Tensor[(10, 256), float32] span=StatefulPartitionedCall/sequential_1/dense_1_2/MatMul:0:0 */, meta[relay.Constant][20] /* ty=Tensor[(10), float32] span=StatefulPartitionedCall/sequential_1/dense_1_2/Add.StatefulPartitionedCall/sequential_1/dense_1_2/Add/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 10), float32] */;
  %69 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, Primitive=1) -> Tensor[(1, 10), float32] {
    nn.softmax(%p0, axis=1) /* ty=Tensor[(1, 10), float32] span=StatefulPartitionedCall/sequential_1/dense_1_2/Softmax:0:0 */
  } /* ty=fn (Tensor[(1, 10), float32]) -> Tensor[(1, 10), float32] */;
  %69(%68) /* ty=Tensor[(1, 10), float32] */
}


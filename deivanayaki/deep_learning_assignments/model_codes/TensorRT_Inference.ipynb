{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "HVKMgli70TD0",
        "outputId": "125da766-6b97-46c7-cce3-01270bf7e85f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/onnx/tensorflow-onnx\n",
            "  Cloning https://github.com/onnx/tensorflow-onnx to /tmp/pip-req-build-mzyro2oy\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/onnx/tensorflow-onnx /tmp/pip-req-build-mzyro2oy\n",
            "  Resolved https://github.com/onnx/tensorflow-onnx to commit 72c4bdec6163bc2a41ebc60de0c3e12398118d1f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from tf2onnx==1.16.1) (1.26.4)\n",
            "Collecting onnx>=1.4.1 (from tf2onnx==1.16.1)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tf2onnx==1.16.1) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tf2onnx==1.16.1) (1.17.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.11/dist-packages (from tf2onnx==1.16.1) (24.12.23)\n",
            "Collecting protobuf~=3.20 (from tf2onnx==1.16.1)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx==1.16.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx==1.16.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx==1.16.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx==1.16.1) (2024.12.14)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tf2onnx\n",
            "  Building wheel for tf2onnx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf2onnx: filename=tf2onnx-1.16.1-py3-none-any.whl size=456694 sha256=83fb4b612ce6678630a80f093e30218aa795aaf91a2ac137bdc13482c6482cba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-90lab14c/wheels/b9/59/ad/796a7a463db709029269f06ba58ff2526b3c71aa9e922d47e9\n",
            "Successfully built tf2onnx\n",
            "Installing collected packages: protobuf, onnx, tf2onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.17.0 protobuf-3.20.3 tf2onnx-1.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "cabdcb8f7df64584b49c1d32a592fcf3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install git+https://github.com/onnx/tensorflow-onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "class Conv2DBatchNormReLU(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, l2=1e-4, kernel_size=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv2d = tf.keras.layers.Conv2D(\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_initializer=tf.keras.initializers.HeUniform(),\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2),\n",
        "        )\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization(\n",
        "            epsilon=1e-5, momentum=0.9,\n",
        "            beta_regularizer=tf.keras.regularizers.l2(l2),\n",
        "            gamma_regularizer=tf.keras.regularizers.l2(l2)\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.conv2d(inputs)\n",
        "        x = self.batch_norm(x, training=training)\n",
        "        return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "class ResNet9Block(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, l2=1e-4, kernel_size=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_bn_relu_1 = Conv2DBatchNormReLU(filters=filters, l2=l2, kernel_size=kernel_size)\n",
        "        self.conv_bn_relu_2 = Conv2DBatchNormReLU(filters=filters, l2=l2, kernel_size=kernel_size)\n",
        "        self.downsample = tf.keras.layers.Conv2D(\n",
        "            filters=filters,\n",
        "            kernel_size=1,\n",
        "            strides=2,\n",
        "            padding='SAME',\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2)\n",
        "        )\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization(\n",
        "            epsilon=1e-5, momentum=0.9,\n",
        "            beta_regularizer=tf.keras.regularizers.l2(l2),\n",
        "            gamma_regularizer=tf.keras.regularizers.l2(l2)\n",
        "        )\n",
        "        self.max_pool2d = tf.keras.layers.MaxPool2D(pool_size=2)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        shortcut = self.downsample(inputs)\n",
        "        shortcut = self.batch_norm(shortcut, training=training)\n",
        "\n",
        "        x = self.conv_bn_relu_1(inputs, training=training)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.conv_bn_relu_2(x, training=training)\n",
        "\n",
        "        return tf.nn.relu(x + shortcut)\n",
        "\n",
        "\n",
        "# Load the model with custom layers\n",
        "model = tf.keras.models.load_model(\n",
        "    \"/content/CIFAR-TUNED-RESNET9-AUG.keras\",\n",
        "    custom_objects={\n",
        "        \"Conv2DBatchNormReLU\": Conv2DBatchNormReLU,\n",
        "        \"ResNet9Block\": ResNet9Block\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUv3PLwg1t0v",
        "outputId": "0c08379d-3ab9-4efa-f3db-99f0f202ac6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'conv2d_batch_norm_re_lu', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'res_net9_block', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'conv2d_batch_norm_re_lu_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'res_net9_block_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, \"tmp_model\")\n",
        "!python3 -m tf2onnx.convert --saved-model tmp_model --output \"model.onnx\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FdBvYQd1xim",
        "outputId": "09dd6c15-4348-41d1-e1aa-48fadc2e3e65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-22 16:28:42.455901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-22 16:28:42.475702: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-22 16:28:42.481736: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-22 16:28:43.720861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "2025-01-22 16:28:46,432 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1737563326.440800    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563326.496405    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563326.496787    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563326.497972    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563326.498236    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563326.498464    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563326.691926    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563326.692310    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-01-22 16:28:46.692510: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1737563326.692627    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-01-22 16:28:46,693 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2025-01-22 16:28:48,136 - INFO - Signatures found in model: [serving_default].\n",
            "2025-01-22 16:28:48,136 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2025-01-22 16:28:48,136 - INFO - Output names: ['output_0']\n",
            "I0000 00:00:1737563328.176986    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563328.177188    2551 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "I0000 00:00:1737563328.177803    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563328.178045    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563328.178247    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563328.178462    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563328.178627    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.040885    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.041292    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.041558    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.041862    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.042094    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.191219    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.191427    2551 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "I0000 00:00:1737563329.191913    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.192137    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.192306    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.192526    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1737563329.192712    2551 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-01-22 16:28:49,485 - INFO - Using tensorflow=2.17.1, onnx=1.17.0, tf2onnx=1.16.1/72c4bd\n",
            "2025-01-22 16:28:49,485 - INFO - Using opset <onnx, 15>\n",
            "2025-01-22 16:28:49,551 - INFO - Computed 0 values for constant folding\n",
            "2025-01-22 16:28:49,672 - INFO - Optimizing ONNX model\n",
            "2025-01-22 16:28:49,833 - INFO - After optimization: Add -8 (10->2), GlobalAveragePool +1 (0->1), Identity -2 (2->0), ReduceMean -1 (1->0), Squeeze +1 (0->1), Transpose -21 (22->1)\n",
            "2025-01-22 16:28:49,857 - INFO - \n",
            "2025-01-22 16:28:49,857 - INFO - Successfully converted TensorFlow model tmp_model to ONNX\n",
            "2025-01-22 16:28:49,857 - INFO - Model inputs: ['inputs']\n",
            "2025-01-22 16:28:49,857 - INFO - Model outputs: ['output_0']\n",
            "2025-01-22 16:28:49,857 - INFO - ONNX model is saved at model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y python3-libnvinfer libnvinfer-bin libnvinfer-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgL0qP3o2Gdu",
        "outputId": "29bf68bc-c36d-4bca-8a1f-eebffe8dcf1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,646 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,228 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [53.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,860 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,561 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,519 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,619 kB]\n",
            "Fetched 19.9 MB in 4s (4,445 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libnvinfer-dispatch10 libnvinfer-headers-dev libnvinfer-lean10 libnvinfer-plugin10\n",
            "  libnvinfer-vc-plugin10 libnvinfer10 libnvonnxparsers10\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-bin libnvinfer-dev libnvinfer-dispatch10 libnvinfer-headers-dev libnvinfer-lean10\n",
            "  libnvinfer-plugin10 libnvinfer-vc-plugin10 libnvinfer10 libnvonnxparsers10 python3-libnvinfer\n",
            "0 upgraded, 10 newly installed, 0 to remove and 64 not upgraded.\n",
            "Need to get 2,507 MB of archives.\n",
            "After this operation, 6,510 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer10 10.7.0.23-1+cuda12.6 [1,240 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-lean10 10.7.0.23-1+cuda12.6 [8,232 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin10 10.7.0.23-1+cuda12.6 [9,874 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-vc-plugin10 10.7.0.23-1+cuda12.6 [223 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dispatch10 10.7.0.23-1+cuda12.6 [213 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvonnxparsers10 10.7.0.23-1+cuda12.6 [1,324 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-bin 10.7.0.23-1+cuda12.6 [461 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-headers-dev 10.7.0.23-1+cuda12.6 [106 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dev 10.7.0.23-1+cuda12.6 [1,246 MB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  python3-libnvinfer 10.7.0.23-1+cuda12.6 [810 kB]\n",
            "Fetched 2,507 MB in 57s (44.3 MB/s)\n",
            "Selecting previously unselected package libnvinfer10.\n",
            "(Reading database ... 124561 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libnvinfer10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-lean10.\n",
            "Preparing to unpack .../1-libnvinfer-lean10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-lean10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-plugin10.\n",
            "Preparing to unpack .../2-libnvinfer-plugin10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-vc-plugin10.\n",
            "Preparing to unpack .../3-libnvinfer-vc-plugin10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-vc-plugin10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-dispatch10.\n",
            "Preparing to unpack .../4-libnvinfer-dispatch10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-dispatch10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvonnxparsers10.\n",
            "Preparing to unpack .../5-libnvonnxparsers10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvonnxparsers10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-bin.\n",
            "Preparing to unpack .../6-libnvinfer-bin_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-bin (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-headers-dev.\n",
            "Preparing to unpack .../7-libnvinfer-headers-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-headers-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-dev.\n",
            "Preparing to unpack .../8-libnvinfer-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package python3-libnvinfer.\n",
            "Preparing to unpack .../9-python3-libnvinfer_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking python3-libnvinfer (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-headers-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-plugin10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-vc-plugin10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvonnxparsers10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-dispatch10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-lean10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up python3-libnvinfer (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-bin (10.7.0.23-1+cuda12.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dpkg -l | grep nvinfer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAyNfrsr2LGK",
        "outputId": "c4449133-608a-4460-a0d4-9736217674a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ii  libnvinfer-bin                         10.7.0.23-1+cuda12.6                    amd64        TensorRT binaries\n",
            "ii  libnvinfer-dev                         10.7.0.23-1+cuda12.6                    amd64        TensorRT development libraries\n",
            "ii  libnvinfer-dispatch10                  10.7.0.23-1+cuda12.6                    amd64        TensorRT dispatch runtime library\n",
            "ii  libnvinfer-headers-dev                 10.7.0.23-1+cuda12.6                    amd64        TensorRT development headers\n",
            "ii  libnvinfer-lean10                      10.7.0.23-1+cuda12.6                    amd64        TensorRT lean runtime library\n",
            "ii  libnvinfer-plugin10                    10.7.0.23-1+cuda12.6                    amd64        TensorRT plugin libraries\n",
            "ii  libnvinfer-vc-plugin10                 10.7.0.23-1+cuda12.6                    amd64        TensorRT vc-plugin library\n",
            "ii  libnvinfer10                           10.7.0.23-1+cuda12.6                    amd64        TensorRT runtime libraries\n",
            "ii  python3-libnvinfer                     10.7.0.23-1+cuda12.6                    amd64        Python 3 bindings for TensorRT standard runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/src/tensorrt/bin/trtexec --onnx=/content/model.onnx --saveEngine=/content/model.trt --fp16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWHqULg82NoE",
        "outputId": "ebb1bddc-1b9d-488e-e2fa-5d796f123841"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "&&&& RUNNING TensorRT.trtexec [TensorRT v100700] [b23] # /usr/src/tensorrt/bin/trtexec --onnx=/content/model.onnx --saveEngine=/content/model.trt --fp16\n",
            "[01/22/2025-16:35:32] [I] === Model Options ===\n",
            "[01/22/2025-16:35:32] [I] Format: ONNX\n",
            "[01/22/2025-16:35:32] [I] Model: /content/model.onnx\n",
            "[01/22/2025-16:35:32] [I] Output:\n",
            "[01/22/2025-16:35:32] [I] === Build Options ===\n",
            "[01/22/2025-16:35:32] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
            "[01/22/2025-16:35:32] [I] avgTiming: 8\n",
            "[01/22/2025-16:35:32] [I] Precision: FP32+FP16\n",
            "[01/22/2025-16:35:32] [I] LayerPrecisions: \n",
            "[01/22/2025-16:35:32] [I] Layer Device Types: \n",
            "[01/22/2025-16:35:32] [I] Calibration: \n",
            "[01/22/2025-16:35:32] [I] Refit: Disabled\n",
            "[01/22/2025-16:35:32] [I] Strip weights: Disabled\n",
            "[01/22/2025-16:35:32] [I] Version Compatible: Disabled\n",
            "[01/22/2025-16:35:32] [I] ONNX Plugin InstanceNorm: Disabled\n",
            "[01/22/2025-16:35:32] [I] TensorRT runtime: full\n",
            "[01/22/2025-16:35:32] [I] Lean DLL Path: \n",
            "[01/22/2025-16:35:32] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
            "[01/22/2025-16:35:32] [I] Exclude Lean Runtime: Disabled\n",
            "[01/22/2025-16:35:32] [I] Sparsity: Disabled\n",
            "[01/22/2025-16:35:32] [I] Safe mode: Disabled\n",
            "[01/22/2025-16:35:32] [I] Build DLA standalone loadable: Disabled\n",
            "[01/22/2025-16:35:32] [I] Allow GPU fallback for DLA: Disabled\n",
            "[01/22/2025-16:35:32] [I] DirectIO mode: Disabled\n",
            "[01/22/2025-16:35:32] [I] Restricted mode: Disabled\n",
            "[01/22/2025-16:35:32] [I] Skip inference: Disabled\n",
            "[01/22/2025-16:35:32] [I] Save engine: /content/model.trt\n",
            "[01/22/2025-16:35:32] [I] Load engine: \n",
            "[01/22/2025-16:35:32] [I] Profiling verbosity: 0\n",
            "[01/22/2025-16:35:32] [I] Tactic sources: Using default tactic sources\n",
            "[01/22/2025-16:35:32] [I] timingCacheMode: local\n",
            "[01/22/2025-16:35:32] [I] timingCacheFile: \n",
            "[01/22/2025-16:35:32] [I] Enable Compilation Cache: Enabled\n",
            "[01/22/2025-16:35:32] [I] Enable Monitor Memory: Disabled\n",
            "[01/22/2025-16:35:32] [I] errorOnTimingCacheMiss: Disabled\n",
            "[01/22/2025-16:35:32] [I] Preview Features: Use default preview flags.\n",
            "[01/22/2025-16:35:32] [I] MaxAuxStreams: -1\n",
            "[01/22/2025-16:35:32] [I] BuilderOptimizationLevel: -1\n",
            "[01/22/2025-16:35:32] [I] MaxTactics: -1\n",
            "[01/22/2025-16:35:32] [I] Calibration Profile Index: 0\n",
            "[01/22/2025-16:35:32] [I] Weight Streaming: Disabled\n",
            "[01/22/2025-16:35:32] [I] Runtime Platform: Same As Build\n",
            "[01/22/2025-16:35:32] [I] Debug Tensors: \n",
            "[01/22/2025-16:35:32] [I] Input(s)s format: fp32:CHW\n",
            "[01/22/2025-16:35:32] [I] Output(s)s format: fp32:CHW\n",
            "[01/22/2025-16:35:32] [I] Input build shapes: model\n",
            "[01/22/2025-16:35:32] [I] Input calibration shapes: model\n",
            "[01/22/2025-16:35:32] [I] === System Options ===\n",
            "[01/22/2025-16:35:32] [I] Device: 0\n",
            "[01/22/2025-16:35:32] [I] DLACore: \n",
            "[01/22/2025-16:35:32] [I] Plugins:\n",
            "[01/22/2025-16:35:32] [I] setPluginsToSerialize:\n",
            "[01/22/2025-16:35:32] [I] dynamicPlugins:\n",
            "[01/22/2025-16:35:32] [I] ignoreParsedPluginLibs: 0\n",
            "[01/22/2025-16:35:32] [I] \n",
            "[01/22/2025-16:35:32] [I] === Inference Options ===\n",
            "[01/22/2025-16:35:32] [I] Batch: Explicit\n",
            "[01/22/2025-16:35:32] [I] Input inference shapes: model\n",
            "[01/22/2025-16:35:32] [I] Iterations: 10\n",
            "[01/22/2025-16:35:32] [I] Duration: 3s (+ 200ms warm up)\n",
            "[01/22/2025-16:35:32] [I] Sleep time: 0ms\n",
            "[01/22/2025-16:35:32] [I] Idle time: 0ms\n",
            "[01/22/2025-16:35:32] [I] Inference Streams: 1\n",
            "[01/22/2025-16:35:32] [I] ExposeDMA: Disabled\n",
            "[01/22/2025-16:35:32] [I] Data transfers: Enabled\n",
            "[01/22/2025-16:35:32] [I] Spin-wait: Disabled\n",
            "[01/22/2025-16:35:32] [I] Multithreading: Disabled\n",
            "[01/22/2025-16:35:32] [I] CUDA Graph: Disabled\n",
            "[01/22/2025-16:35:32] [I] Separate profiling: Disabled\n",
            "[01/22/2025-16:35:32] [I] Time Deserialize: Disabled\n",
            "[01/22/2025-16:35:32] [I] Time Refit: Disabled\n",
            "[01/22/2025-16:35:32] [I] NVTX verbosity: 0\n",
            "[01/22/2025-16:35:32] [I] Persistent Cache Ratio: 0\n",
            "[01/22/2025-16:35:32] [I] Optimization Profile Index: 0\n",
            "[01/22/2025-16:35:32] [I] Weight Streaming Budget: 100.000000%\n",
            "[01/22/2025-16:35:32] [I] Inputs:\n",
            "[01/22/2025-16:35:32] [I] Debug Tensor Save Destinations:\n",
            "[01/22/2025-16:35:32] [I] === Reporting Options ===\n",
            "[01/22/2025-16:35:32] [I] Verbose: Disabled\n",
            "[01/22/2025-16:35:32] [I] Averages: 10 inferences\n",
            "[01/22/2025-16:35:32] [I] Percentiles: 90,95,99\n",
            "[01/22/2025-16:35:32] [I] Dump refittable layers:Disabled\n",
            "[01/22/2025-16:35:32] [I] Dump output: Disabled\n",
            "[01/22/2025-16:35:32] [I] Profile: Disabled\n",
            "[01/22/2025-16:35:32] [I] Export timing to JSON file: \n",
            "[01/22/2025-16:35:32] [I] Export output to JSON file: \n",
            "[01/22/2025-16:35:32] [I] Export profile to JSON file: \n",
            "[01/22/2025-16:35:32] [I] \n",
            "[01/22/2025-16:35:32] [I] === Device Information ===\n",
            "[01/22/2025-16:35:32] [I] Available Devices: \n",
            "[01/22/2025-16:35:32] [I]   Device 0: \"Tesla T4\" UUID: GPU-2d7c2c49-e2bc-2838-d11c-2cf31cdcc577\n",
            "[01/22/2025-16:35:32] [I] Selected Device: Tesla T4\n",
            "[01/22/2025-16:35:32] [I] Selected Device ID: 0\n",
            "[01/22/2025-16:35:32] [I] Selected Device UUID: GPU-2d7c2c49-e2bc-2838-d11c-2cf31cdcc577\n",
            "[01/22/2025-16:35:32] [I] Compute Capability: 7.5\n",
            "[01/22/2025-16:35:32] [I] SMs: 40\n",
            "[01/22/2025-16:35:32] [I] Device Global Memory: 15102 MiB\n",
            "[01/22/2025-16:35:32] [I] Shared Memory per SM: 64 KiB\n",
            "[01/22/2025-16:35:32] [I] Memory Bus Width: 256 bits (ECC enabled)\n",
            "[01/22/2025-16:35:32] [I] Application Compute Clock Rate: 1.59 GHz\n",
            "[01/22/2025-16:35:32] [I] Application Memory Clock Rate: 5.001 GHz\n",
            "[01/22/2025-16:35:32] [I] \n",
            "[01/22/2025-16:35:32] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
            "[01/22/2025-16:35:32] [I] \n",
            "[01/22/2025-16:35:32] [I] TensorRT version: 10.7.0\n",
            "[01/22/2025-16:35:32] [I] Loading standard plugins\n",
            "[01/22/2025-16:35:33] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 17, GPU 331 (MiB)\n",
            "[01/22/2025-16:35:41] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +955, GPU +194, now: CPU 1128, GPU 525 (MiB)\n",
            "[01/22/2025-16:35:41] [I] Start parsing network model.\n",
            "[01/22/2025-16:35:41] [I] [TRT] ----------------------------------------------------------------\n",
            "[01/22/2025-16:35:41] [I] [TRT] Input filename:   /content/model.onnx\n",
            "[01/22/2025-16:35:41] [I] [TRT] ONNX IR version:  0.0.8\n",
            "[01/22/2025-16:35:41] [I] [TRT] Opset version:    15\n",
            "[01/22/2025-16:35:41] [I] [TRT] Producer name:    tf2onnx\n",
            "[01/22/2025-16:35:41] [I] [TRT] Producer version: 1.16.1 72c4bd\n",
            "[01/22/2025-16:35:41] [I] [TRT] Domain:           \n",
            "[01/22/2025-16:35:41] [I] [TRT] Model version:    0\n",
            "[01/22/2025-16:35:41] [I] [TRT] Doc string:       \n",
            "[01/22/2025-16:35:41] [I] [TRT] ----------------------------------------------------------------\n",
            "[01/22/2025-16:35:41] [I] Finished parsing network model. Parse time: 0.188711\n",
            "[01/22/2025-16:35:41] [W] Dynamic dimensions required for input: inputs, but no shapes were provided. Automatically overriding shape to: 1x32x32x3\n",
            "[01/22/2025-16:35:41] [I] Set shape of input tensor inputs for optimization profile 0 to: MIN=1x32x32x3 OPT=1x32x32x3 MAX=1x32x32x3\n",
            "[01/22/2025-16:35:41] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[01/22/2025-16:35:41] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[01/22/2025-16:35:41] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "[01/22/2025-16:35:48] [I] [TRT] Compiler backend is used during engine build.\n",
            "[01/22/2025-16:35:52] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
            "[01/22/2025-16:35:54] [I] [TRT] Total Host Persistent Memory: 60816 bytes\n",
            "[01/22/2025-16:35:54] [I] [TRT] Total Device Persistent Memory: 0 bytes\n",
            "[01/22/2025-16:35:54] [I] [TRT] Max Scratch Memory: 512 bytes\n",
            "[01/22/2025-16:35:54] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 15 steps to complete.\n",
            "[01/22/2025-16:35:54] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.15753ms to assign 3 blocks to 15 nodes requiring 425984 bytes.\n",
            "[01/22/2025-16:35:54] [I] [TRT] Total Activation Memory: 425984 bytes\n",
            "[01/22/2025-16:35:54] [I] [TRT] Total Weights Memory: 8417024 bytes\n",
            "[01/22/2025-16:35:54] [I] [TRT] Compiler backend is used during engine execution.\n",
            "[01/22/2025-16:35:54] [I] [TRT] Engine generation completed in 12.9818 seconds.\n",
            "[01/22/2025-16:35:54] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 3 MiB, GPU 21 MiB\n",
            "[01/22/2025-16:35:54] [I] Engine built in 13.0106 sec.\n",
            "[01/22/2025-16:35:54] [I] Created engine with size: 8.47049 MiB\n",
            "[01/22/2025-16:35:54] [I] [TRT] Loaded engine size: 8 MiB\n",
            "[01/22/2025-16:35:54] [I] Engine deserialized in 0.0110034 sec.\n",
            "[01/22/2025-16:35:54] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 8 (MiB)\n",
            "[01/22/2025-16:35:54] [I] Setting persistentCacheLimit to 0 bytes.\n",
            "[01/22/2025-16:35:54] [I] Created execution context with device memory size: 0.40625 MiB\n",
            "[01/22/2025-16:35:54] [I] Using random values for input inputs\n",
            "[01/22/2025-16:35:54] [I] Input binding for inputs with dimensions 1x32x32x3 is created.\n",
            "[01/22/2025-16:35:54] [I] Output binding for output_0 with dimensions 1x10 is created.\n",
            "[01/22/2025-16:35:54] [I] Starting inference\n",
            "[01/22/2025-16:35:57] [I] Warmup completed 552 queries over 200 ms\n",
            "[01/22/2025-16:35:57] [I] Timing trace has 13343 queries over 3.00068 s\n",
            "[01/22/2025-16:35:57] [I] \n",
            "[01/22/2025-16:35:57] [I] === Trace details ===\n",
            "[01/22/2025-16:35:57] [I] Trace averages of 10 runs:\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.347621 ms - Host latency: 0.362099 ms (enqueue 0.221494 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.342029 ms - Host latency: 0.365558 ms (enqueue 0.226332 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.330342 ms - Host latency: 0.343254 ms (enqueue 0.22321 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.271159 ms - Host latency: 0.316052 ms (enqueue 0.198772 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.22231 ms - Host latency: 0.256323 ms (enqueue 0.162912 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.192436 ms - Host latency: 0.20484 ms (enqueue 0.151874 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.188397 ms - Host latency: 0.200455 ms (enqueue 0.144186 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.186319 ms - Host latency: 0.199269 ms (enqueue 0.142999 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18434 ms - Host latency: 0.197694 ms (enqueue 0.136337 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18333 ms - Host latency: 0.19711 ms (enqueue 0.141876 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.180046 ms - Host latency: 0.19288 ms (enqueue 0.138162 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.180392 ms - Host latency: 0.193787 ms (enqueue 0.138889 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.187402 ms - Host latency: 0.199493 ms (enqueue 0.145331 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.192081 ms - Host latency: 0.205722 ms (enqueue 0.146931 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.191563 ms - Host latency: 0.204189 ms (enqueue 0.144783 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.194095 ms - Host latency: 0.206595 ms (enqueue 0.148477 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18886 ms - Host latency: 0.202151 ms (enqueue 0.151334 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.237975 ms - Host latency: 0.250743 ms (enqueue 0.193079 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.182216 ms - Host latency: 0.194955 ms (enqueue 0.139255 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.180075 ms - Host latency: 0.19312 ms (enqueue 0.13857 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179494 ms - Host latency: 0.191878 ms (enqueue 0.136876 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179181 ms - Host latency: 0.191336 ms (enqueue 0.137094 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179367 ms - Host latency: 0.191524 ms (enqueue 0.129762 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179692 ms - Host latency: 0.192003 ms (enqueue 0.119875 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179697 ms - Host latency: 0.192953 ms (enqueue 0.119232 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18035 ms - Host latency: 0.193137 ms (enqueue 0.123766 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.180063 ms - Host latency: 0.192612 ms (enqueue 0.12301 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179916 ms - Host latency: 0.192639 ms (enqueue 0.124808 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17915 ms - Host latency: 0.192279 ms (enqueue 0.13884 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.186877 ms - Host latency: 0.203589 ms (enqueue 0.150729 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.26105 ms - Host latency: 0.272174 ms (enqueue 0.194904 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.258875 ms - Host latency: 0.293497 ms (enqueue 0.190213 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.260403 ms - Host latency: 0.296259 ms (enqueue 0.187701 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.269623 ms - Host latency: 0.288971 ms (enqueue 0.202182 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.27912 ms - Host latency: 0.299371 ms (enqueue 0.213803 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.262949 ms - Host latency: 0.274942 ms (enqueue 0.187021 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.270377 ms - Host latency: 0.301712 ms (enqueue 0.202087 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.278149 ms - Host latency: 0.289203 ms (enqueue 0.211768 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.230087 ms - Host latency: 0.242011 ms (enqueue 0.165622 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.193747 ms - Host latency: 0.206259 ms (enqueue 0.149155 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.199512 ms - Host latency: 0.212561 ms (enqueue 0.158112 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.224054 ms - Host latency: 0.236865 ms (enqueue 0.175333 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.196704 ms - Host latency: 0.20911 ms (enqueue 0.147125 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.181546 ms - Host latency: 0.194476 ms (enqueue 0.133939 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.180658 ms - Host latency: 0.192523 ms (enqueue 0.13233 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.189047 ms - Host latency: 0.201385 ms (enqueue 0.144131 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.180966 ms - Host latency: 0.193161 ms (enqueue 0.138354 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.186823 ms - Host latency: 0.200177 ms (enqueue 0.140759 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178949 ms - Host latency: 0.193179 ms (enqueue 0.1224 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178571 ms - Host latency: 0.190509 ms (enqueue 0.14567 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18175 ms - Host latency: 0.194067 ms (enqueue 0.144434 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.189426 ms - Host latency: 0.202982 ms (enqueue 0.146295 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.415033 ms - Host latency: 0.430063 ms (enqueue 0.371814 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.183002 ms - Host latency: 0.195523 ms (enqueue 0.137585 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.191696 ms - Host latency: 0.203879 ms (enqueue 0.147064 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.203284 ms - Host latency: 0.215128 ms (enqueue 0.16243 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179233 ms - Host latency: 0.192514 ms (enqueue 0.122424 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178769 ms - Host latency: 0.191501 ms (enqueue 0.126999 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178909 ms - Host latency: 0.191803 ms (enqueue 0.120413 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.189227 ms - Host latency: 0.202457 ms (enqueue 0.143793 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.269263 ms - Host latency: 0.289636 ms (enqueue 0.205832 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.267975 ms - Host latency: 0.28743 ms (enqueue 0.201581 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.312286 ms - Host latency: 0.367191 ms (enqueue 0.251715 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.272742 ms - Host latency: 0.292511 ms (enqueue 0.203683 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.273209 ms - Host latency: 0.284744 ms (enqueue 0.206647 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.272577 ms - Host latency: 0.289792 ms (enqueue 0.206482 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.282562 ms - Host latency: 0.293222 ms (enqueue 0.213547 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.270883 ms - Host latency: 0.281906 ms (enqueue 0.202432 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.283029 ms - Host latency: 0.294028 ms (enqueue 0.218314 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.271878 ms - Host latency: 0.283383 ms (enqueue 0.192242 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.264346 ms - Host latency: 0.275516 ms (enqueue 0.19216 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.257349 ms - Host latency: 0.268109 ms (enqueue 0.179172 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.259531 ms - Host latency: 0.271036 ms (enqueue 0.179956 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.296799 ms - Host latency: 0.314261 ms (enqueue 0.229755 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.271173 ms - Host latency: 0.282245 ms (enqueue 0.20723 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.270874 ms - Host latency: 0.281885 ms (enqueue 0.199631 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.223166 ms - Host latency: 0.234863 ms (enqueue 0.151578 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18717 ms - Host latency: 0.199979 ms (enqueue 0.151343 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179391 ms - Host latency: 0.192035 ms (enqueue 0.127798 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.181082 ms - Host latency: 0.194192 ms (enqueue 0.141489 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.180023 ms - Host latency: 0.192923 ms (enqueue 0.133926 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178284 ms - Host latency: 0.191101 ms (enqueue 0.122046 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17977 ms - Host latency: 0.193625 ms (enqueue 0.132724 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178555 ms - Host latency: 0.191028 ms (enqueue 0.137094 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170779 ms - Host latency: 0.183371 ms (enqueue 0.132773 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170627 ms - Host latency: 0.183502 ms (enqueue 0.120364 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.181122 ms - Host latency: 0.192902 ms (enqueue 0.144647 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178998 ms - Host latency: 0.190887 ms (enqueue 0.13754 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18269 ms - Host latency: 0.195285 ms (enqueue 0.140387 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.180887 ms - Host latency: 0.192715 ms (enqueue 0.139154 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.185593 ms - Host latency: 0.198926 ms (enqueue 0.143365 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166995 ms - Host latency: 0.179086 ms (enqueue 0.12901 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166174 ms - Host latency: 0.177899 ms (enqueue 0.126505 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172437 ms - Host latency: 0.18685 ms (enqueue 0.134912 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.176276 ms - Host latency: 0.18851 ms (enqueue 0.139188 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172476 ms - Host latency: 0.184009 ms (enqueue 0.131961 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166522 ms - Host latency: 0.179004 ms (enqueue 0.127591 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170694 ms - Host latency: 0.183722 ms (enqueue 0.132993 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.210483 ms - Host latency: 0.250369 ms (enqueue 0.163916 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.246451 ms - Host latency: 0.263651 ms (enqueue 0.187494 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.248294 ms - Host latency: 0.258789 ms (enqueue 0.190509 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.250851 ms - Host latency: 0.26781 ms (enqueue 0.196988 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.258752 ms - Host latency: 0.293265 ms (enqueue 0.205832 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.258853 ms - Host latency: 0.269519 ms (enqueue 0.201453 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.257938 ms - Host latency: 0.274225 ms (enqueue 0.206476 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.268716 ms - Host latency: 0.279745 ms (enqueue 0.213861 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.264841 ms - Host latency: 0.291275 ms (enqueue 0.21329 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.259506 ms - Host latency: 0.306064 ms (enqueue 0.20025 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.266159 ms - Host latency: 0.285815 ms (enqueue 0.214548 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.257532 ms - Host latency: 0.300485 ms (enqueue 0.201486 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.240836 ms - Host latency: 0.262393 ms (enqueue 0.17428 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.238763 ms - Host latency: 0.249863 ms (enqueue 0.159686 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.237772 ms - Host latency: 0.248364 ms (enqueue 0.167377 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.242413 ms - Host latency: 0.257886 ms (enqueue 0.178629 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.240601 ms - Host latency: 0.251352 ms (enqueue 0.166721 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.241266 ms - Host latency: 0.252209 ms (enqueue 0.169708 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.240363 ms - Host latency: 0.261963 ms (enqueue 0.162769 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.235501 ms - Host latency: 0.246704 ms (enqueue 0.164615 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.243903 ms - Host latency: 0.263159 ms (enqueue 0.170551 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.31821 ms - Host latency: 0.350293 ms (enqueue 0.261905 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.31438 ms - Host latency: 0.356833 ms (enqueue 0.262775 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.246146 ms - Host latency: 0.281348 ms (enqueue 0.186661 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.250305 ms - Host latency: 0.260687 ms (enqueue 0.191425 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.267725 ms - Host latency: 0.294055 ms (enqueue 0.213281 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.258636 ms - Host latency: 0.279742 ms (enqueue 0.206531 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.267267 ms - Host latency: 0.295636 ms (enqueue 0.211249 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.260382 ms - Host latency: 0.299023 ms (enqueue 0.198914 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.249329 ms - Host latency: 0.268335 ms (enqueue 0.195673 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167462 ms - Host latency: 0.178857 ms (enqueue 0.119244 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.180597 ms - Host latency: 0.196179 ms (enqueue 0.139886 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.182404 ms - Host latency: 0.194653 ms (enqueue 0.139984 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.186218 ms - Host latency: 0.198163 ms (enqueue 0.146234 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170526 ms - Host latency: 0.182458 ms (enqueue 0.130872 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18222 ms - Host latency: 0.196283 ms (enqueue 0.137463 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18053 ms - Host latency: 0.193005 ms (enqueue 0.14176 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.188977 ms - Host latency: 0.20083 ms (enqueue 0.142114 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.197247 ms - Host latency: 0.21073 ms (enqueue 0.153259 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.182642 ms - Host latency: 0.195667 ms (enqueue 0.140582 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.188458 ms - Host latency: 0.200494 ms (enqueue 0.144025 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.186414 ms - Host latency: 0.199359 ms (enqueue 0.144452 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178247 ms - Host latency: 0.190521 ms (enqueue 0.137952 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169891 ms - Host latency: 0.181744 ms (enqueue 0.128992 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164368 ms - Host latency: 0.176282 ms (enqueue 0.126715 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164874 ms - Host latency: 0.176471 ms (enqueue 0.127466 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.182477 ms - Host latency: 0.197528 ms (enqueue 0.140125 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17442 ms - Host latency: 0.186536 ms (enqueue 0.1362 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.163684 ms - Host latency: 0.175385 ms (enqueue 0.126459 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164081 ms - Host latency: 0.176135 ms (enqueue 0.127466 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167645 ms - Host latency: 0.179498 ms (enqueue 0.129285 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170599 ms - Host latency: 0.182489 ms (enqueue 0.130383 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166272 ms - Host latency: 0.178754 ms (enqueue 0.128082 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.182288 ms - Host latency: 0.194318 ms (enqueue 0.142761 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179395 ms - Host latency: 0.191302 ms (enqueue 0.134058 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171783 ms - Host latency: 0.183698 ms (enqueue 0.133179 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.175415 ms - Host latency: 0.187946 ms (enqueue 0.136218 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179993 ms - Host latency: 0.191809 ms (enqueue 0.143921 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.174927 ms - Host latency: 0.187073 ms (enqueue 0.133087 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169525 ms - Host latency: 0.181335 ms (enqueue 0.130878 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165894 ms - Host latency: 0.177594 ms (enqueue 0.12818 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168738 ms - Host latency: 0.180554 ms (enqueue 0.129242 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.162769 ms - Host latency: 0.174268 ms (enqueue 0.123682 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16391 ms - Host latency: 0.175946 ms (enqueue 0.123431 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171039 ms - Host latency: 0.18313 ms (enqueue 0.132257 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17312 ms - Host latency: 0.194067 ms (enqueue 0.130719 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165369 ms - Host latency: 0.177643 ms (enqueue 0.12616 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.163971 ms - Host latency: 0.17597 ms (enqueue 0.126617 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168146 ms - Host latency: 0.180133 ms (enqueue 0.131244 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.181128 ms - Host latency: 0.195203 ms (enqueue 0.141852 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.173199 ms - Host latency: 0.185187 ms (enqueue 0.133374 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178314 ms - Host latency: 0.190485 ms (enqueue 0.137476 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169983 ms - Host latency: 0.183136 ms (enqueue 0.129901 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16499 ms - Host latency: 0.17677 ms (enqueue 0.126923 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169574 ms - Host latency: 0.181616 ms (enqueue 0.13277 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.1729 ms - Host latency: 0.185498 ms (enqueue 0.133557 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.18089 ms - Host latency: 0.192639 ms (enqueue 0.1409 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171002 ms - Host latency: 0.183746 ms (enqueue 0.130084 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16994 ms - Host latency: 0.181934 ms (enqueue 0.131049 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168683 ms - Host latency: 0.180505 ms (enqueue 0.13078 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17738 ms - Host latency: 0.188922 ms (enqueue 0.142194 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.174719 ms - Host latency: 0.18645 ms (enqueue 0.138 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168359 ms - Host latency: 0.180048 ms (enqueue 0.129425 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.163135 ms - Host latency: 0.174817 ms (enqueue 0.126025 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.162878 ms - Host latency: 0.174408 ms (enqueue 0.12702 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172174 ms - Host latency: 0.18476 ms (enqueue 0.131256 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.177478 ms - Host latency: 0.190961 ms (enqueue 0.134296 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.173907 ms - Host latency: 0.186365 ms (enqueue 0.134198 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170465 ms - Host latency: 0.182593 ms (enqueue 0.13092 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178296 ms - Host latency: 0.190533 ms (enqueue 0.137152 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.179785 ms - Host latency: 0.19375 ms (enqueue 0.137512 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.194098 ms - Host latency: 0.207263 ms (enqueue 0.149426 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.352698 ms - Host latency: 0.366742 ms (enqueue 0.311566 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.233411 ms - Host latency: 0.255115 ms (enqueue 0.194592 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.202045 ms - Host latency: 0.214874 ms (enqueue 0.157104 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.190369 ms - Host latency: 0.202539 ms (enqueue 0.149231 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.195911 ms - Host latency: 0.208252 ms (enqueue 0.156268 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.251202 ms - Host latency: 0.262933 ms (enqueue 0.206842 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.270551 ms - Host latency: 0.285095 ms (enqueue 0.227856 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.302014 ms - Host latency: 0.314496 ms (enqueue 0.259253 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.197247 ms - Host latency: 0.21192 ms (enqueue 0.155682 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.196521 ms - Host latency: 0.208008 ms (enqueue 0.152081 ms)\n",
            "[01/22/2025-16:35:57] [I] ... Omitting 9343 lines\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.162744 ms - Host latency: 0.174854 ms (enqueue 0.127954 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170093 ms - Host latency: 0.182837 ms (enqueue 0.135522 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167578 ms - Host latency: 0.179785 ms (enqueue 0.131079 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169214 ms - Host latency: 0.181958 ms (enqueue 0.134766 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165918 ms - Host latency: 0.178052 ms (enqueue 0.130469 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166553 ms - Host latency: 0.179297 ms (enqueue 0.131226 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.163159 ms - Host latency: 0.175269 ms (enqueue 0.130151 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164331 ms - Host latency: 0.176099 ms (enqueue 0.128882 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166406 ms - Host latency: 0.178711 ms (enqueue 0.130933 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169141 ms - Host latency: 0.181372 ms (enqueue 0.131934 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168018 ms - Host latency: 0.180322 ms (enqueue 0.13042 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.204761 ms - Host latency: 0.241113 ms (enqueue 0.166968 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166113 ms - Host latency: 0.178394 ms (enqueue 0.12876 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171655 ms - Host latency: 0.183521 ms (enqueue 0.134155 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.175 ms - Host latency: 0.187646 ms (enqueue 0.138306 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.175488 ms - Host latency: 0.187451 ms (enqueue 0.139868 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17937 ms - Host latency: 0.19292 ms (enqueue 0.141797 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168335 ms - Host latency: 0.1802 ms (enqueue 0.130371 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169458 ms - Host latency: 0.180908 ms (enqueue 0.132275 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16665 ms - Host latency: 0.179028 ms (enqueue 0.129907 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17002 ms - Host latency: 0.182739 ms (enqueue 0.130371 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169922 ms - Host latency: 0.183496 ms (enqueue 0.131079 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165894 ms - Host latency: 0.177759 ms (enqueue 0.129736 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164624 ms - Host latency: 0.1771 ms (enqueue 0.129736 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164575 ms - Host latency: 0.17627 ms (enqueue 0.128198 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16814 ms - Host latency: 0.180225 ms (enqueue 0.131689 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16731 ms - Host latency: 0.17915 ms (enqueue 0.13125 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167139 ms - Host latency: 0.179004 ms (enqueue 0.129346 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169849 ms - Host latency: 0.181348 ms (enqueue 0.132275 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164673 ms - Host latency: 0.176709 ms (enqueue 0.127539 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164575 ms - Host latency: 0.176294 ms (enqueue 0.12771 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170239 ms - Host latency: 0.182544 ms (enqueue 0.133179 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167651 ms - Host latency: 0.179468 ms (enqueue 0.1302 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169312 ms - Host latency: 0.182031 ms (enqueue 0.132227 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165137 ms - Host latency: 0.176978 ms (enqueue 0.127197 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166113 ms - Host latency: 0.178613 ms (enqueue 0.131543 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167456 ms - Host latency: 0.179468 ms (enqueue 0.131641 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167822 ms - Host latency: 0.17959 ms (enqueue 0.12998 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17417 ms - Host latency: 0.186035 ms (enqueue 0.136646 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167822 ms - Host latency: 0.179932 ms (enqueue 0.131689 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.199463 ms - Host latency: 0.212427 ms (enqueue 0.167554 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168408 ms - Host latency: 0.180981 ms (enqueue 0.131006 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167456 ms - Host latency: 0.179614 ms (enqueue 0.132471 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.163599 ms - Host latency: 0.176489 ms (enqueue 0.112842 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.174341 ms - Host latency: 0.187451 ms (enqueue 0.132861 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169922 ms - Host latency: 0.182104 ms (enqueue 0.133252 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169971 ms - Host latency: 0.183008 ms (enqueue 0.133472 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166943 ms - Host latency: 0.178833 ms (enqueue 0.131323 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167065 ms - Host latency: 0.178638 ms (enqueue 0.131104 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165796 ms - Host latency: 0.178345 ms (enqueue 0.128857 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171387 ms - Host latency: 0.183423 ms (enqueue 0.133643 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169531 ms - Host latency: 0.181372 ms (enqueue 0.132275 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164819 ms - Host latency: 0.176196 ms (enqueue 0.129126 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167798 ms - Host latency: 0.179858 ms (enqueue 0.131763 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168921 ms - Host latency: 0.180713 ms (enqueue 0.131934 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170288 ms - Host latency: 0.182617 ms (enqueue 0.133228 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167285 ms - Host latency: 0.179639 ms (enqueue 0.129932 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167651 ms - Host latency: 0.179932 ms (enqueue 0.130908 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170386 ms - Host latency: 0.182227 ms (enqueue 0.133667 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168018 ms - Host latency: 0.180127 ms (enqueue 0.131006 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165674 ms - Host latency: 0.177686 ms (enqueue 0.129077 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.176147 ms - Host latency: 0.187842 ms (enqueue 0.140356 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171436 ms - Host latency: 0.183887 ms (enqueue 0.134473 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171484 ms - Host latency: 0.18374 ms (enqueue 0.134473 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171191 ms - Host latency: 0.183472 ms (enqueue 0.134009 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170166 ms - Host latency: 0.18186 ms (enqueue 0.132349 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170068 ms - Host latency: 0.182104 ms (enqueue 0.135352 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.173755 ms - Host latency: 0.186304 ms (enqueue 0.133545 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.178125 ms - Host latency: 0.189917 ms (enqueue 0.137866 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171021 ms - Host latency: 0.18374 ms (enqueue 0.13291 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171143 ms - Host latency: 0.183081 ms (enqueue 0.135254 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169189 ms - Host latency: 0.181445 ms (enqueue 0.13313 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171143 ms - Host latency: 0.184155 ms (enqueue 0.133862 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.173071 ms - Host latency: 0.185107 ms (enqueue 0.135156 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16792 ms - Host latency: 0.179517 ms (enqueue 0.133057 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16875 ms - Host latency: 0.181812 ms (enqueue 0.129419 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167432 ms - Host latency: 0.179395 ms (enqueue 0.133228 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.176099 ms - Host latency: 0.189795 ms (enqueue 0.137329 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17041 ms - Host latency: 0.183911 ms (enqueue 0.131299 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.174463 ms - Host latency: 0.187646 ms (enqueue 0.13623 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166528 ms - Host latency: 0.178833 ms (enqueue 0.130005 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167163 ms - Host latency: 0.179321 ms (enqueue 0.131055 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165601 ms - Host latency: 0.178198 ms (enqueue 0.130103 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169263 ms - Host latency: 0.181445 ms (enqueue 0.131494 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170972 ms - Host latency: 0.183154 ms (enqueue 0.133545 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16543 ms - Host latency: 0.177197 ms (enqueue 0.130542 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169067 ms - Host latency: 0.182471 ms (enqueue 0.132812 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170435 ms - Host latency: 0.182153 ms (enqueue 0.133374 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169604 ms - Host latency: 0.181396 ms (enqueue 0.133496 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168384 ms - Host latency: 0.180225 ms (enqueue 0.131055 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172119 ms - Host latency: 0.18457 ms (enqueue 0.133057 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168335 ms - Host latency: 0.180615 ms (enqueue 0.131323 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167505 ms - Host latency: 0.179297 ms (enqueue 0.131958 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171021 ms - Host latency: 0.183325 ms (enqueue 0.134082 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165991 ms - Host latency: 0.178418 ms (enqueue 0.130176 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16853 ms - Host latency: 0.180225 ms (enqueue 0.132373 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17168 ms - Host latency: 0.183887 ms (enqueue 0.134937 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168677 ms - Host latency: 0.180908 ms (enqueue 0.132544 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169238 ms - Host latency: 0.180957 ms (enqueue 0.132666 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168945 ms - Host latency: 0.180884 ms (enqueue 0.132275 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17251 ms - Host latency: 0.18501 ms (enqueue 0.134351 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164478 ms - Host latency: 0.176318 ms (enqueue 0.117065 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167871 ms - Host latency: 0.179932 ms (enqueue 0.128564 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168091 ms - Host latency: 0.180688 ms (enqueue 0.130444 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167627 ms - Host latency: 0.179443 ms (enqueue 0.132471 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169482 ms - Host latency: 0.181519 ms (enqueue 0.131445 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16853 ms - Host latency: 0.18186 ms (enqueue 0.131885 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17522 ms - Host latency: 0.186938 ms (enqueue 0.138159 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172754 ms - Host latency: 0.185156 ms (enqueue 0.135889 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169653 ms - Host latency: 0.181543 ms (enqueue 0.131543 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165308 ms - Host latency: 0.1771 ms (enqueue 0.129126 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168433 ms - Host latency: 0.180493 ms (enqueue 0.132666 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170312 ms - Host latency: 0.183179 ms (enqueue 0.137036 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171533 ms - Host latency: 0.184473 ms (enqueue 0.134009 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169507 ms - Host latency: 0.183081 ms (enqueue 0.134082 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171021 ms - Host latency: 0.18269 ms (enqueue 0.133032 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16814 ms - Host latency: 0.179956 ms (enqueue 0.130786 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167749 ms - Host latency: 0.180176 ms (enqueue 0.132007 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.175488 ms - Host latency: 0.187744 ms (enqueue 0.136401 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169531 ms - Host latency: 0.182275 ms (enqueue 0.134253 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170459 ms - Host latency: 0.18252 ms (enqueue 0.130811 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165894 ms - Host latency: 0.177954 ms (enqueue 0.130078 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165625 ms - Host latency: 0.177954 ms (enqueue 0.129199 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168042 ms - Host latency: 0.180029 ms (enqueue 0.131104 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170068 ms - Host latency: 0.18208 ms (enqueue 0.133667 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.174609 ms - Host latency: 0.18728 ms (enqueue 0.133472 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16665 ms - Host latency: 0.178857 ms (enqueue 0.132983 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17312 ms - Host latency: 0.185278 ms (enqueue 0.132593 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167798 ms - Host latency: 0.17959 ms (enqueue 0.129468 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.176514 ms - Host latency: 0.189526 ms (enqueue 0.140381 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16687 ms - Host latency: 0.178613 ms (enqueue 0.130811 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172681 ms - Host latency: 0.184668 ms (enqueue 0.137207 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.181201 ms - Host latency: 0.195117 ms (enqueue 0.140967 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170093 ms - Host latency: 0.182349 ms (enqueue 0.132593 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167578 ms - Host latency: 0.179541 ms (enqueue 0.131177 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.173511 ms - Host latency: 0.188281 ms (enqueue 0.133765 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170898 ms - Host latency: 0.182886 ms (enqueue 0.132739 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170483 ms - Host latency: 0.182568 ms (enqueue 0.133008 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168091 ms - Host latency: 0.179907 ms (enqueue 0.130859 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168213 ms - Host latency: 0.18042 ms (enqueue 0.132422 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165479 ms - Host latency: 0.177734 ms (enqueue 0.128467 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166602 ms - Host latency: 0.17832 ms (enqueue 0.131567 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.173999 ms - Host latency: 0.186182 ms (enqueue 0.13938 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169092 ms - Host latency: 0.181201 ms (enqueue 0.132202 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170337 ms - Host latency: 0.182202 ms (enqueue 0.133984 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172729 ms - Host latency: 0.184766 ms (enqueue 0.134595 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.176343 ms - Host latency: 0.189014 ms (enqueue 0.141016 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170874 ms - Host latency: 0.183179 ms (enqueue 0.13479 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.176611 ms - Host latency: 0.188818 ms (enqueue 0.139331 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.165576 ms - Host latency: 0.178149 ms (enqueue 0.129297 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166431 ms - Host latency: 0.178662 ms (enqueue 0.130469 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170264 ms - Host latency: 0.182397 ms (enqueue 0.133911 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172095 ms - Host latency: 0.184277 ms (enqueue 0.134839 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169141 ms - Host latency: 0.180835 ms (enqueue 0.132227 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.175977 ms - Host latency: 0.187866 ms (enqueue 0.13916 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169067 ms - Host latency: 0.18186 ms (enqueue 0.13335 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170801 ms - Host latency: 0.182471 ms (enqueue 0.133447 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168701 ms - Host latency: 0.181104 ms (enqueue 0.130933 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.173608 ms - Host latency: 0.186035 ms (enqueue 0.141235 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170532 ms - Host latency: 0.182446 ms (enqueue 0.126416 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16543 ms - Host latency: 0.178174 ms (enqueue 0.115649 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.162817 ms - Host latency: 0.177759 ms (enqueue 0.110962 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.176172 ms - Host latency: 0.18916 ms (enqueue 0.139404 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169653 ms - Host latency: 0.181665 ms (enqueue 0.132178 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171045 ms - Host latency: 0.182471 ms (enqueue 0.132593 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172754 ms - Host latency: 0.185156 ms (enqueue 0.1375 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167847 ms - Host latency: 0.180078 ms (enqueue 0.129932 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168994 ms - Host latency: 0.180444 ms (enqueue 0.132617 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.168335 ms - Host latency: 0.179858 ms (enqueue 0.131641 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.164429 ms - Host latency: 0.177002 ms (enqueue 0.12771 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172632 ms - Host latency: 0.184302 ms (enqueue 0.136572 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.17561 ms - Host latency: 0.187354 ms (enqueue 0.134448 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16665 ms - Host latency: 0.17854 ms (enqueue 0.130884 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.1677 ms - Host latency: 0.179858 ms (enqueue 0.132422 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171094 ms - Host latency: 0.183569 ms (enqueue 0.133496 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166919 ms - Host latency: 0.179492 ms (enqueue 0.129639 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16416 ms - Host latency: 0.176147 ms (enqueue 0.12627 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.174878 ms - Host latency: 0.187622 ms (enqueue 0.14021 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167065 ms - Host latency: 0.178711 ms (enqueue 0.129663 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171411 ms - Host latency: 0.183984 ms (enqueue 0.136011 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.172583 ms - Host latency: 0.184912 ms (enqueue 0.137549 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.181885 ms - Host latency: 0.196167 ms (enqueue 0.145361 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.176147 ms - Host latency: 0.188721 ms (enqueue 0.137451 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.181104 ms - Host latency: 0.193652 ms (enqueue 0.141528 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170752 ms - Host latency: 0.182739 ms (enqueue 0.133398 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170459 ms - Host latency: 0.182349 ms (enqueue 0.131934 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167944 ms - Host latency: 0.179761 ms (enqueue 0.131128 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169922 ms - Host latency: 0.18147 ms (enqueue 0.13252 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.16897 ms - Host latency: 0.180884 ms (enqueue 0.134814 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171533 ms - Host latency: 0.183887 ms (enqueue 0.134033 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.169824 ms - Host latency: 0.181274 ms (enqueue 0.133765 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171631 ms - Host latency: 0.183618 ms (enqueue 0.132837 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167236 ms - Host latency: 0.178662 ms (enqueue 0.130615 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.176929 ms - Host latency: 0.188477 ms (enqueue 0.136719 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.171484 ms - Host latency: 0.184766 ms (enqueue 0.134497 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.170483 ms - Host latency: 0.184814 ms (enqueue 0.131689 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.167212 ms - Host latency: 0.178979 ms (enqueue 0.132324 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166846 ms - Host latency: 0.178467 ms (enqueue 0.130957 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.166724 ms - Host latency: 0.179565 ms (enqueue 0.129297 ms)\n",
            "[01/22/2025-16:35:57] [I] Average on 10 runs - GPU latency: 0.241528 ms - Host latency: 0.280347 ms (enqueue 0.203198 ms)\n",
            "[01/22/2025-16:35:57] [I] \n",
            "[01/22/2025-16:35:57] [I] === Performance summary ===\n",
            "[01/22/2025-16:35:57] [I] Throughput: 4446.66 qps\n",
            "[01/22/2025-16:35:57] [I] Latency: min = 0.169678 ms, max = 4.41504 ms, mean = 0.214161 ms, median = 0.192139 ms, percentile(90%) = 0.264893 ms, percentile(95%) = 0.283569 ms, percentile(99%) = 0.359772 ms\n",
            "[01/22/2025-16:35:57] [I] Enqueue Time: min = 0.0961914 ms, max = 4.38751 ms, mean = 0.153392 ms, median = 0.140137 ms, percentile(90%) = 0.194275 ms, percentile(95%) = 0.206421 ms, percentile(99%) = 0.239502 ms\n",
            "[01/22/2025-16:35:57] [I] H2D Latency: min = 0.00585938 ms, max = 0.883057 ms, mean = 0.00956687 ms, median = 0.00708008 ms, percentile(90%) = 0.00805664 ms, percentile(95%) = 0.00991821 ms, percentile(99%) = 0.0860596 ms\n",
            "[01/22/2025-16:35:57] [I] GPU Compute Time: min = 0.159668 ms, max = 4.39954 ms, mean = 0.199485 ms, median = 0.179688 ms, percentile(90%) = 0.251343 ms, percentile(95%) = 0.26181 ms, percentile(99%) = 0.290558 ms\n",
            "[01/22/2025-16:35:57] [I] D2H Latency: min = 0.00341797 ms, max = 1.9707 ms, mean = 0.00510882 ms, median = 0.00439453 ms, percentile(90%) = 0.00634766 ms, percentile(95%) = 0.0065918 ms, percentile(99%) = 0.00830078 ms\n",
            "[01/22/2025-16:35:57] [I] Total Host Walltime: 3.00068 s\n",
            "[01/22/2025-16:35:57] [I] Total GPU Compute Time: 2.66173 s\n",
            "[01/22/2025-16:35:57] [W] * GPU compute time is unstable, with coefficient of variance = 38.2047%.\n",
            "[01/22/2025-16:35:57] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
            "[01/22/2025-16:35:57] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
            "[01/22/2025-16:35:57] [I] \n",
            "&&&& PASSED TensorRT.trtexec [TensorRT v100700] [b23] # /usr/src/tensorrt/bin/trtexec --onnx=/content/model.onnx --saveEngine=/content/model.trt --fp16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0kUIwQd2RR_",
        "outputId": "2787b26b-970b-445b-8353-3b73232d61c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-10.7.0.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12==10.7.0 (from tensorrt)\n",
            "  Downloading tensorrt_cu12-10.7.0.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt, tensorrt_cu12\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.7.0-py2.py3-none-any.whl size=16336 sha256=ae30e24e93ea34417988b2afa0dad05bc32ca6058d11ae965e59cb7d43c7d623\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/d9/8e/9c3f248355e21ed1a3a2c923b21f48ac7dabae3e2f7ec31ce7\n",
            "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.7.0-py2.py3-none-any.whl size=17551 sha256=87cdd19e97125d726599b4fecb3a47d03c9d7cdc1fe2257839ad29e4967e726d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/b8/b1/c8b6c821e7dc08ebe34022fbf297874db54a6c23a3876210a3\n",
            "Successfully built tensorrt tensorrt_cu12\n",
            "Installing collected packages: tensorrt_cu12, tensorrt\n",
            "Successfully installed tensorrt-10.7.0 tensorrt_cu12-10.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifYGa4ez2TS-",
        "outputId": "94848931-cd73-4d47-f92f-c6d04a65a2c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2025.1.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp311-cp311-linux_x86_64.whl size=660362 sha256=4d78eb084d732053aa2fe202f943646b1c4005b7764041e135adf438dd1f1452\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/66/50/c65e6116d7e0e16abe0f7c19b50327f76724ccfefbdc61a1b9\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.8 pycuda-2024.1.2 pytools-2025.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import tensorrt as trt\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# CIFAR-10 class labels for prediction\n",
        "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "def preprocess_image(image, input_shape):\n",
        "    \"\"\"\n",
        "    Preprocess the input CIFAR-10 image: resize, normalize, and format for TensorRT.\n",
        "    CIFAR-10 images are 32x32, resizing them to 224x224.\n",
        "    \"\"\"\n",
        "    image = Image.fromarray(image).convert('RGB')  # Convert to RGB\n",
        "    image = image.resize((input_shape[2], input_shape[1]))  # Resize to 224x224\n",
        "    image_array = np.array(image, dtype=np.float32).transpose(2, 0, 1)  # Convert from HWC to CHW\n",
        "    image_array /= 255.0  # Normalize to [0, 1] (assuming input data is normalized this way)\n",
        "    return np.expand_dims(image_array, axis=0).copy()  # Add batch dimension and make it contiguous\n",
        "\n",
        "def load_engine(engine_path):\n",
        "    \"\"\"\n",
        "    Load the TensorRT engine.\n",
        "    \"\"\"\n",
        "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "    with open(engine_path, 'rb') as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
        "        return runtime.deserialize_cuda_engine(f.read())\n",
        "\n",
        "def infer(engine, context, image_array, input_shape, output_shape):\n",
        "    \"\"\"\n",
        "    Perform inference on a single image and measure latency.\n",
        "    \"\"\"\n",
        "    # Allocate device memory\n",
        "    d_input = cuda.mem_alloc(int(np.prod(input_shape) * np.dtype(np.float32).itemsize))  # cast to int\n",
        "    d_output = cuda.mem_alloc(int(np.prod(output_shape) * np.dtype(np.float32).itemsize))  # cast to int\n",
        "\n",
        "    # Transfer input to GPU\n",
        "    cuda.memcpy_htod(d_input, image_array)\n",
        "\n",
        "    # Perform inference\n",
        "    bindings = [int(d_input), int(d_output)]\n",
        "    start_time = time.time()\n",
        "    context.execute_v2(bindings=bindings)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Transfer output back to CPU\n",
        "    output = np.empty(output_shape, dtype=np.float32)\n",
        "    cuda.memcpy_dtoh(output, d_output)\n",
        "\n",
        "    latency = (end_time - start_time) * 1000  # Convert to milliseconds\n",
        "    return output, latency\n",
        "\n",
        "def measure_latency_and_predict(model_path, image, input_shape=(1, 3, 224, 224), output_shape=(1, 10)):\n",
        "    \"\"\"\n",
        "    Load the TensorRT model, preprocess the image, run inference, and measure latency.\n",
        "    \"\"\"\n",
        "    # Load TensorRT engine\n",
        "    engine = load_engine(model_path)\n",
        "    context = engine.create_execution_context()\n",
        "\n",
        "    # Preprocess the CIFAR-10 image\n",
        "    image_array = preprocess_image(image, input_shape).astype(np.float32)\n",
        "\n",
        "    # Perform inference\n",
        "    output, latency = infer(engine, context, image_array, input_shape, output_shape)\n",
        "\n",
        "    # Get the predicted class label index (highest probability)\n",
        "    predicted_class = np.argmax(output)\n",
        "\n",
        "    return predicted_class, latency\n",
        "# Main Script: Processing CIFAR-10 Image\n",
        "(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()  # Load CIFAR-10 dataset\n",
        "ind=13\n",
        "sample_image = x_test[ind]  # Select a sample image from the test set\n",
        "\n",
        "# Plot the sample image\n",
        "plt.imshow(sample_image)\n",
        "plt.title(f\"Sample Image (Label: {class_labels[y_test[ind][0]]})\")\n",
        "plt.show()\n",
        "\n",
        "# Specify the TensorRT engine path\n",
        "engine_path = \"model.trt\"  # Path to your TensorRT engine (make sure it's compiled and saved)\n",
        "\n",
        "# Measure latency and make prediction using the TensorRT model\n",
        "predicted_class, latency = measure_latency_and_predict(engine_path, sample_image)\n",
        "\n",
        "# Print the prediction and latency\n",
        "print(f\"Predicted label: {class_labels[predicted_class]}\")\n",
        "print(f\"Latency: {latency*0.001:.6f} s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "7bbjbNwe2Vo6",
        "outputId": "824df5e4-672d-4bb2-8ac1-239a9643155c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: horse\n",
            "Latency: 0.000419 s\n"
          ]
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import graph_executor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"mnist_resnet_final.onnx\"\n",
    "onnx_model = onnx.load(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"input\"\n",
    "input_shape = (1, 224, 224, 3)\n",
    "input_dtype = \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"llvm\"\n",
    "shape_dict = {input_name: input_shape}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = tvm.device(target, 0)  # Use 0 for the first device\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.random.randn(*input_shape).astype(input_dtype)\n",
    "module.set_input(input_name, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (1, 10)\n"
     ]
    }
   ],
   "source": [
    "output_index = 0  # Replace with the correct output index if there are multiple outputs\n",
    "output = module.get_output(output_index).asnumpy()\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model_path = \"tvm _model.so\"\n",
    "lib.export_library(compiled_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%input: Tensor[(1, 224, 224, 3), float32] /* ty=Tensor[(1, 224, 224, 3), float32] span=model/conv2d/BiasAdd__6.input:0:0 */) -> Tensor[(1, 10), float32] {\n",
      "  %0 = transpose(%input, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 3, 224, 224), float32] span=model/conv2d/BiasAdd__6:0:0 */;\n",
      "  %1 = nn.conv2d(%0, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] span=model/conv2d/BiasAdd.model/conv2d/Conv2D/ReadVariableOp:0:0:0 */, strides=[2, 2], padding=[2, 2, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] span=model/conv2d/BiasAdd:0:0 */;\n",
      "  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(64), float32] span=model/conv2d/BiasAdd.model/conv2d/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 64, 112, 112), float32] span=model/conv2d/BiasAdd:0:0 */;\n",
      "  %3 = nn.relu(%2) /* ty=Tensor[(1, 64, 112, 112), float32] span=model/conv2d/Relu:0:0 */;\n",
      "  %4 = nn.batch_norm(%3, meta[relay.Constant][2] /* ty=Tensor[(64), float32] span=model/batch_normalization/FusedBatchNormV3.model/batch_normalization/ReadVariableOp:0:0:0 */, meta[relay.Constant][3] /* ty=Tensor[(64), float32] span=model/batch_normalization/FusedBatchNormV3.model/batch_normalization/ReadVariableOp_1:0:0:0 */, meta[relay.Constant][4] /* ty=Tensor[(64), float32] span=model/batch_normalization/FusedBatchNormV3.model/batch_normalization/FusedBatchNormV3/ReadVariableOp:0:0:0 */, meta[relay.Constant][5] /* ty=Tensor[(64), float32] span=model/batch_normalization/FusedBatchNormV3.model/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0:0:0 */, epsilon=0.001f) /* ty=(Tensor[(1, 64, 112, 112), float32], Tensor[(64), float32], Tensor[(64), float32]) span=model/batch_normalization/FusedBatchNormV3:0:0 */;\n",
      "  %5 = %4.0 /* ty=Tensor[(1, 64, 112, 112), float32] span=model/batch_normalization/FusedBatchNormV3:0:0 */;\n",
      "  %6 = nn.max_pool2d(%5, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/max_pooling2d/MaxPool:0:0 */;\n",
      "  %7 = nn.conv2d(%6, meta[relay.Constant][6] /* ty=Tensor[(64, 64, 3, 3), float32] span=model/conv2d_1/BiasAdd.model/conv2d_1/Conv2D/ReadVariableOp:0:0:0 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_1/BiasAdd:0:0 */;\n",
      "  %8 = nn.bias_add(%7, meta[relay.Constant][7] /* ty=Tensor[(64), float32] span=model/conv2d_1/BiasAdd.model/conv2d_1/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_1/BiasAdd:0:0 */;\n",
      "  %9 = nn.relu(%8) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_1/Relu:0:0 */;\n",
      "  %10 = nn.batch_norm(%9, meta[relay.Constant][8] /* ty=Tensor[(64), float32] span=model/batch_normalization_1/FusedBatchNormV3.model/batch_normalization_1/ReadVariableOp:0:0:0 */, meta[relay.Constant][9] /* ty=Tensor[(64), float32] span=model/batch_normalization_1/FusedBatchNormV3.model/batch_normalization_1/ReadVariableOp_1:0:0:0 */, meta[relay.Constant][10] /* ty=Tensor[(64), float32] span=model/batch_normalization_1/FusedBatchNormV3.model/batch_normalization_1/FusedBatchNormV3/ReadVariableOp:0:0:0 */, meta[relay.Constant][11] /* ty=Tensor[(64), float32] span=model/batch_normalization_1/FusedBatchNormV3.model/batch_normalization_1/FusedBatchNormV3/ReadVariableOp_1:0:0:0 */, epsilon=0.001f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) span=model/batch_normalization_1/FusedBatchNormV3:0:0 */;\n",
      "  %11 = %10.0 /* ty=Tensor[(1, 64, 56, 56), float32] span=model/batch_normalization_1/FusedBatchNormV3:0:0 */;\n",
      "  %12 = nn.conv2d(%11, meta[relay.Constant][12] /* ty=Tensor[(64, 64, 3, 3), float32] span=model/conv2d_2/BiasAdd.model/conv2d_2/BiasAdd_weights_fused_bn:0:0 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_2/BiasAdd:0:0 */;\n",
      "  %13 = nn.bias_add(%12, meta[relay.Constant][13] /* ty=Tensor[(64), float32] span=model/conv2d_2/BiasAdd.model/conv2d_2/BiasAdd_bias_fused_bn:0:0 */) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_2/BiasAdd:0:0 */;\n",
      "  %14 = add(%13, %6) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/add/add:0:0 */;\n",
      "  %15 = nn.relu(%14) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/re_lu/Relu:0:0 */;\n",
      "  %16 = nn.conv2d(%15, meta[relay.Constant][14] /* ty=Tensor[(64, 64, 3, 3), float32] span=model/conv2d_3/BiasAdd.model/conv2d_3/Conv2D/ReadVariableOp:0:0:0 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_3/BiasAdd:0:0 */;\n",
      "  %17 = nn.bias_add(%16, meta[relay.Constant][15] /* ty=Tensor[(64), float32] span=model/conv2d_3/BiasAdd.model/conv2d_3/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_3/BiasAdd:0:0 */;\n",
      "  %18 = nn.relu(%17) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_3/Relu:0:0 */;\n",
      "  %19 = nn.batch_norm(%18, meta[relay.Constant][16] /* ty=Tensor[(64), float32] span=model/batch_normalization_3/FusedBatchNormV3.model/batch_normalization_3/ReadVariableOp:0:0:0 */, meta[relay.Constant][17] /* ty=Tensor[(64), float32] span=model/batch_normalization_3/FusedBatchNormV3.model/batch_normalization_3/ReadVariableOp_1:0:0:0 */, meta[relay.Constant][18] /* ty=Tensor[(64), float32] span=model/batch_normalization_3/FusedBatchNormV3.model/batch_normalization_3/FusedBatchNormV3/ReadVariableOp:0:0:0 */, meta[relay.Constant][19] /* ty=Tensor[(64), float32] span=model/batch_normalization_3/FusedBatchNormV3.model/batch_normalization_3/FusedBatchNormV3/ReadVariableOp_1:0:0:0 */, epsilon=0.001f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) span=model/batch_normalization_3/FusedBatchNormV3:0:0 */;\n",
      "  %20 = %19.0 /* ty=Tensor[(1, 64, 56, 56), float32] span=model/batch_normalization_3/FusedBatchNormV3:0:0 */;\n",
      "  %21 = nn.conv2d(%20, meta[relay.Constant][20] /* ty=Tensor[(64, 64, 3, 3), float32] span=model/conv2d_4/BiasAdd.model/conv2d_4/BiasAdd_weights_fused_bn:0:0 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_4/BiasAdd:0:0 */;\n",
      "  %22 = nn.bias_add(%21, meta[relay.Constant][21] /* ty=Tensor[(64), float32] span=model/conv2d_4/BiasAdd.model/conv2d_4/BiasAdd_bias_fused_bn:0:0 */) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/conv2d_4/BiasAdd:0:0 */;\n",
      "  %23 = add(%22, %15) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/add_1/add:0:0 */;\n",
      "  %24 = nn.relu(%23) /* ty=Tensor[(1, 64, 56, 56), float32] span=model/re_lu_1/Relu:0:0 */;\n",
      "  %25 = nn.conv2d(%24, meta[relay.Constant][22] /* ty=Tensor[(128, 64, 3, 3), float32] span=model/conv2d_6/BiasAdd.model/conv2d_6/Conv2D/ReadVariableOp:0:0:0 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_6/BiasAdd:0:0 */;\n",
      "  %26 = nn.bias_add(%25, meta[relay.Constant][23] /* ty=Tensor[(128), float32] span=model/conv2d_6/BiasAdd.model/conv2d_6/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_6/BiasAdd:0:0 */;\n",
      "  %27 = nn.relu(%26) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_6/Relu:0:0 */;\n",
      "  %28 = nn.batch_norm(%27, meta[relay.Constant][24] /* ty=Tensor[(128), float32] span=model/batch_normalization_5/FusedBatchNormV3.model/batch_normalization_5/ReadVariableOp:0:0:0 */, meta[relay.Constant][25] /* ty=Tensor[(128), float32] span=model/batch_normalization_5/FusedBatchNormV3.model/batch_normalization_5/ReadVariableOp_1:0:0:0 */, meta[relay.Constant][26] /* ty=Tensor[(128), float32] span=model/batch_normalization_5/FusedBatchNormV3.model/batch_normalization_5/FusedBatchNormV3/ReadVariableOp:0:0:0 */, meta[relay.Constant][27] /* ty=Tensor[(128), float32] span=model/batch_normalization_5/FusedBatchNormV3.model/batch_normalization_5/FusedBatchNormV3/ReadVariableOp_1:0:0:0 */, epsilon=0.001f) /* ty=(Tensor[(1, 128, 56, 56), float32], Tensor[(128), float32], Tensor[(128), float32]) span=model/batch_normalization_5/FusedBatchNormV3:0:0 */;\n",
      "  %29 = %28.0 /* ty=Tensor[(1, 128, 56, 56), float32] span=model/batch_normalization_5/FusedBatchNormV3:0:0 */;\n",
      "  %30 = nn.conv2d(%29, meta[relay.Constant][28] /* ty=Tensor[(128, 128, 3, 3), float32] span=model/conv2d_7/BiasAdd.model/conv2d_7/BiasAdd_weights_fused_bn:0:0 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_7/BiasAdd:0:0 */;\n",
      "  %31 = nn.conv2d(%24, meta[relay.Constant][30] /* ty=Tensor[(128, 64, 1, 1), float32] span=model/conv2d_5/BiasAdd.model/conv2d_5/Conv2D/ReadVariableOp:0:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_5/BiasAdd:0:0 */;\n",
      "  %32 = nn.bias_add(%30, meta[relay.Constant][29] /* ty=Tensor[(128), float32] span=model/conv2d_7/BiasAdd.model/conv2d_7/BiasAdd_bias_fused_bn:0:0 */) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_7/BiasAdd:0:0 */;\n",
      "  %33 = nn.bias_add(%31, meta[relay.Constant][31] /* ty=Tensor[(128), float32] span=model/conv2d_5/BiasAdd.model/conv2d_5/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_5/BiasAdd:0:0 */;\n",
      "  %34 = add(%32, %33) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/add_2/add:0:0 */;\n",
      "  %35 = nn.relu(%34) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/re_lu_2/Relu:0:0 */;\n",
      "  %36 = nn.conv2d(%35, meta[relay.Constant][32] /* ty=Tensor[(128, 128, 3, 3), float32] span=model/conv2d_8/BiasAdd.model/conv2d_8/Conv2D/ReadVariableOp:0:0:0 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_8/BiasAdd:0:0 */;\n",
      "  %37 = nn.bias_add(%36, meta[relay.Constant][33] /* ty=Tensor[(128), float32] span=model/conv2d_8/BiasAdd.model/conv2d_8/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_8/BiasAdd:0:0 */;\n",
      "  %38 = nn.relu(%37) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_8/Relu:0:0 */;\n",
      "  %39 = nn.batch_norm(%38, meta[relay.Constant][34] /* ty=Tensor[(128), float32] span=model/batch_normalization_7/FusedBatchNormV3.model/batch_normalization_7/ReadVariableOp:0:0:0 */, meta[relay.Constant][35] /* ty=Tensor[(128), float32] span=model/batch_normalization_7/FusedBatchNormV3.model/batch_normalization_7/ReadVariableOp_1:0:0:0 */, meta[relay.Constant][36] /* ty=Tensor[(128), float32] span=model/batch_normalization_7/FusedBatchNormV3.model/batch_normalization_7/FusedBatchNormV3/ReadVariableOp:0:0:0 */, meta[relay.Constant][37] /* ty=Tensor[(128), float32] span=model/batch_normalization_7/FusedBatchNormV3.model/batch_normalization_7/FusedBatchNormV3/ReadVariableOp_1:0:0:0 */, epsilon=0.001f) /* ty=(Tensor[(1, 128, 56, 56), float32], Tensor[(128), float32], Tensor[(128), float32]) span=model/batch_normalization_7/FusedBatchNormV3:0:0 */;\n",
      "  %40 = %39.0 /* ty=Tensor[(1, 128, 56, 56), float32] span=model/batch_normalization_7/FusedBatchNormV3:0:0 */;\n",
      "  %41 = nn.conv2d(%40, meta[relay.Constant][38] /* ty=Tensor[(128, 128, 3, 3), float32] span=model/conv2d_9/BiasAdd.model/conv2d_9/BiasAdd_weights_fused_bn:0:0 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_9/BiasAdd:0:0 */;\n",
      "  %42 = nn.bias_add(%41, meta[relay.Constant][39] /* ty=Tensor[(128), float32] span=model/conv2d_9/BiasAdd.model/conv2d_9/BiasAdd_bias_fused_bn:0:0 */) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/conv2d_9/BiasAdd:0:0 */;\n",
      "  %43 = add(%42, %35) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/add_3/add:0:0 */;\n",
      "  %44 = nn.relu(%43) /* ty=Tensor[(1, 128, 56, 56), float32] span=model/re_lu_3/Relu:0:0 */;\n",
      "  %45 = nn.global_avg_pool2d(%44) /* ty=Tensor[(1, 128, 1, 1), float32] span=model/global_average_pooling2d/Mean:0:0 */;\n",
      "  %46 = squeeze(%45, axis=[2, 3]) /* ty=Tensor[(1, 128), float32] span=model/global_average_pooling2d/Mean_Squeeze__127:0:0 */;\n",
      "  %47 = nn.dense(%46, meta[relay.Constant][40] /* ty=Tensor[(256, 128), float32] span=model/dense/MatMul:0:0 */, units=None, out_dtype=\"float32\") /* ty=Tensor[(1, 256), float32] span=model/dense/MatMul:0:0 */;\n",
      "  %48 = add(%47, meta[relay.Constant][41] /* ty=Tensor[(256), float32] span=model/dense/BiasAdd.model/dense/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 256), float32] span=model/dense/BiasAdd:0:0 */;\n",
      "  %49 = nn.relu(%48) /* ty=Tensor[(1, 256), float32] span=model/dense/Relu:0:0 */;\n",
      "  %50 = nn.dense(%49, meta[relay.Constant][42] /* ty=Tensor[(10, 256), float32] span=model/dense_1/MatMul:0:0 */, units=None, out_dtype=\"float32\") /* ty=Tensor[(1, 10), float32] span=model/dense_1/MatMul:0:0 */;\n",
      "  %51 = add(%50, meta[relay.Constant][43] /* ty=Tensor[(10), float32] span=model/dense_1/BiasAdd.model/dense_1/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 10), float32] span=model/dense_1/BiasAdd:0:0 */;\n",
      "  nn.softmax(%51, axis=1) /* ty=Tensor[(1, 10), float32] span=model/dense_1/Softmax:0:0 */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"compiled_graph.json\", \"w\") as f:\n",
    "    f.write(lib.get_graph_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import time\n",
    "\n",
    "import time\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tensorflow.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_images, Val_images, Train_labels, Val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to include the channel dimension (for grayscale images)\n",
    "Train_images = Train_images.reshape(-1, 28, 28, 1)\n",
    "Val_images = Val_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Ensure the data is of type float32 and normalized\n",
    "Train_images = Train_images.astype('float32')\n",
    "Val_images = Val_images.astype('float32')\n",
    "test_images = test_images.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_h5_model = tf.keras.models.load_model(r'D:\\Pravin\\MCW\\Assignments\\resnerArchi\\models\\resnet_hypertuned_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "with open(\"models/resnet_abi_model.trt\", \"rb\") as f:\n",
    "    engine_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = trt.Runtime(TRT_LOGGER)\n",
    "engine = runtime.deserialize_cuda_engine(engine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"models/resnet_augmented_model.onnx\"  # Replace with the path to your ONNX model\n",
    "onnx_session = ort.InferenceSession(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infrencing .h5 vs .trt vs .onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRT Model - Average Latency: 0.00183s, Accuracy: 0.0942%\n",
      "ONNX Model - Average Latency: 0.00011s, Accuracy: 0.0942%\n",
      "H5 Model - Average Latency: 0.00611s, Accuracy: 0.0095%\n"
     ]
    }
   ],
   "source": [
    "trt_total_latency = 0.0\n",
    "trt_correct_predictions = 0\n",
    "\n",
    "onnx_total_latency = 0.0\n",
    "onnx_correct_predictions = 0\n",
    "\n",
    "h5_total_latency = 0.0\n",
    "h5_correct_predictions = 0\n",
    "\n",
    "input_shape = (28, 28)\n",
    "output_shape = (1, 10)\n",
    "\n",
    "for i in range(1000):\n",
    "    true_label = test_labels[i]\n",
    "    input_data = test_images[i].reshape(input_shape)\n",
    "\n",
    "    # ----------------------\n",
    "    # TRT Inference\n",
    "    # ----------------------\n",
    "\n",
    "    d_input = cuda.mem_alloc(input_data.nbytes)\n",
    "    d_output = cuda.mem_alloc(np.empty(output_shape, dtype=np.float32).nbytes)\n",
    "    bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "    cuda.memcpy_htod(d_input, input_data)\n",
    "\n",
    "    trt_start_time = time.time()\n",
    "    context.execute_v2(bindings)\n",
    "    trt_end_time = time.time()\n",
    "\n",
    "    trt_latency = trt_end_time - trt_start_time\n",
    "    trt_total_latency += trt_latency\n",
    "\n",
    "    output_data = np.empty(output_shape, dtype=np.float32)\n",
    "    cuda.memcpy_dtoh(output_data, d_output)\n",
    "    trt_predicted_label = np.argmax(output_data)\n",
    "    if true_label == trt_predicted_label:\n",
    "        trt_correct_predictions += 1\n",
    "\n",
    "    # ----------------------\n",
    "    # ONNX Inference\n",
    "    # ----------------------\n",
    "    # Ensure input_data has the shape [batch_size, height, width, channels] for ONNX model\n",
    "    input_data_onnx = input_data.reshape((1, 28, 28, 1))  # Shape: (1, 28, 28, 1)\n",
    "\n",
    "    onnx_start_time = time.time()\n",
    "    onnx_output = onnx_session.run(None, {onnx_session.get_inputs()[0].name: input_data_onnx.astype(np.float32)})[0]\n",
    "    onnx_end_time = time.time()\n",
    "\n",
    "    onnx_latency = onnx_end_time - onnx_start_time\n",
    "    onnx_total_latency += onnx_latency\n",
    "\n",
    "    onnx_predicted_label = np.argmax(onnx_output)\n",
    "    if true_label == onnx_predicted_label:\n",
    "        onnx_correct_predictions += 1\n",
    "\n",
    "    # ----------------------\n",
    "    # H5 Inference\n",
    "    # ----------------------\n",
    "    # Add the channels dimension for the .h5 model\n",
    "    # input_data_h5 = input_data.reshape((1, 28, 28, 1))  # Shape: (1, 28, 28, 1)\n",
    "\n",
    "    h5_start_time = time.time()\n",
    "    h5_output = augmented_h5_model.predict(input_data_h5, verbose=0)  # Assuming augmented_h5_model is loaded\n",
    "    h5_end_time = time.time()\n",
    "\n",
    "    h5_latency = h5_end_time - h5_start_time\n",
    "    h5_total_latency += h5_latency\n",
    "\n",
    "    h5_predicted_label = np.argmax(h5_output)\n",
    "    if true_label == h5_predicted_label:\n",
    "        h5_correct_predictions += 1\n",
    "\n",
    "# ----------------------\n",
    "# Calculate Metrics\n",
    "# ----------------------\n",
    "trt_average_latency = trt_total_latency / len(test_images)\n",
    "trt_accuracy = trt_correct_predictions / len(test_images)\n",
    "\n",
    "onnx_average_latency = onnx_total_latency / len(test_images)\n",
    "onnx_accuracy = onnx_correct_predictions / len(test_images)\n",
    "\n",
    "h5_average_latency = h5_total_latency / len(test_images)\n",
    "h5_accuracy = h5_correct_predictions / len(test_images)\n",
    "\n",
    "# Print results\n",
    "print(f\"TRT Model - Average Latency: {trt_average_latency:.5f}s, Accuracy: {trt_accuracy}%\")\n",
    "print(f\"ONNX Model - Average Latency: {onnx_average_latency:.5f}s, Accuracy: {onnx_accuracy}%\")\n",
    "print(f\"H5 Model - Average Latency: {h5_average_latency:.5f}s, Accuracy: {h5_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

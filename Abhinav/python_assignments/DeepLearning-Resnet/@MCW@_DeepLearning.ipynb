{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc46546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.2458650893730316\n",
      "Epoch 2/25, Loss: 0.07202167023044787\n",
      "Epoch 3/25, Loss: 0.05244105090038416\n",
      "Epoch 4/25, Loss: 0.04148007498296754\n",
      "Epoch 5/25, Loss: 0.03419133901830265\n",
      "Epoch 6/25, Loss: 0.02942045467729712\n",
      "Epoch 7/25, Loss: 0.024943765408990196\n",
      "Epoch 8/25, Loss: 0.02281281545871405\n",
      "Epoch 9/25, Loss: 0.019312328867231575\n",
      "Epoch 10/25, Loss: 0.016814906713857464\n",
      "Epoch 11/25, Loss: 0.015062828617703847\n",
      "Epoch 12/25, Loss: 0.015372558772077624\n",
      "Epoch 13/25, Loss: 0.012928580608654566\n",
      "Epoch 14/25, Loss: 0.01025229639353924\n",
      "Epoch 15/25, Loss: 0.010797202584284423\n",
      "Epoch 16/25, Loss: 0.010401211253421647\n",
      "Epoch 17/25, Loss: 0.007946938997027872\n",
      "Epoch 18/25, Loss: 0.008747007918003464\n",
      "Epoch 19/25, Loss: 0.009062762238956443\n",
      "Epoch 20/25, Loss: 0.007707487706723389\n",
      "Epoch 21/25, Loss: 0.007038458869113373\n",
      "Epoch 22/25, Loss: 0.007218020430296681\n",
      "Epoch 23/25, Loss: 0.008689647627528274\n",
      "Epoch 24/25, Loss: 0.004622160426381923\n",
      "Epoch 25/25, Loss: 0.007249597535165571\n",
      "Accuracy: 99.00%, F1 Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "epochs = 25\n",
    "\n",
    "# Data Preparation\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# LeNet Model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize Model\n",
    "model = LeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, loader):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(loader)}\")\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return all_labels, all_preds\n",
    "\n",
    "train_model(model, train_loader)\n",
    "true_labels, predicted_labels = evaluate_model(model, test_loader)\n",
    "accuracy = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == pred]) / len(true_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%, F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b2ada9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with LR=0.01, Batch Size=32, Optimizer=Adam\n",
      "Epoch 1/25, Loss: 0.5985796714087327\n",
      "Epoch 2/25, Loss: 0.3982830466757218\n",
      "Epoch 3/25, Loss: 0.370960235658288\n",
      "Epoch 4/25, Loss: 0.35840828212797643\n",
      "Epoch 5/25, Loss: 0.3498827578149736\n",
      "Epoch 6/25, Loss: 0.33676523219632604\n",
      "Epoch 7/25, Loss: 0.341860643829902\n",
      "Epoch 8/25, Loss: 0.3411294964564343\n",
      "Epoch 9/25, Loss: 0.3348617584099372\n",
      "Epoch 10/25, Loss: 0.3275609507886072\n",
      "Epoch 11/25, Loss: 0.33790144894917806\n",
      "Epoch 12/25, Loss: 0.3175504847895354\n",
      "Epoch 13/25, Loss: 0.3288730463615308\n",
      "Epoch 14/25, Loss: 0.3241818760889272\n",
      "Epoch 15/25, Loss: 0.3511347201017042\n",
      "Epoch 16/25, Loss: 0.32416921319067477\n",
      "Epoch 17/25, Loss: 0.342156790695712\n",
      "Epoch 18/25, Loss: 0.33454803063198923\n",
      "Epoch 19/25, Loss: 0.31661266812359296\n",
      "Epoch 20/25, Loss: 0.363572636140883\n",
      "Epoch 21/25, Loss: 0.32621568090158204\n",
      "Epoch 22/25, Loss: 0.33905524789094926\n",
      "Epoch 23/25, Loss: 0.3194112988010049\n",
      "Epoch 24/25, Loss: 0.32206148709729315\n",
      "Epoch 25/25, Loss: 0.3562324930942307\n",
      "Accuracy: 95.01%, F1 Score: 0.95\n",
      "Training with LR=0.01, Batch Size=32, Optimizer=SGD\n",
      "Epoch 1/25, Loss: 1.943768398507436\n",
      "Epoch 2/25, Loss: 0.6210335622310639\n",
      "Epoch 3/25, Loss: 0.36065296028256416\n",
      "Epoch 4/25, Loss: 0.26334284783105055\n",
      "Epoch 5/25, Loss: 0.21080705100099245\n",
      "Epoch 6/25, Loss: 0.17898346695403258\n",
      "Epoch 7/25, Loss: 0.1642475354038179\n",
      "Epoch 8/25, Loss: 0.14728652521719535\n",
      "Epoch 9/25, Loss: 0.13903428089569012\n",
      "Epoch 10/25, Loss: 0.12855021731530628\n",
      "Epoch 11/25, Loss: 0.12180625627549986\n",
      "Epoch 12/25, Loss: 0.11617480460032821\n",
      "Epoch 13/25, Loss: 0.10912798859858885\n",
      "Epoch 14/25, Loss: 0.1055245203588158\n",
      "Epoch 15/25, Loss: 0.0992249545627584\n",
      "Epoch 16/25, Loss: 0.09931913748160004\n",
      "Epoch 17/25, Loss: 0.09543957824409008\n",
      "Epoch 18/25, Loss: 0.08966946113593877\n",
      "Epoch 19/25, Loss: 0.08920392556227744\n",
      "Epoch 20/25, Loss: 0.0849746176522846\n",
      "Epoch 21/25, Loss: 0.08622991504321496\n",
      "Epoch 22/25, Loss: 0.08472234390887122\n",
      "Epoch 23/25, Loss: 0.08180832416520764\n",
      "Epoch 24/25, Loss: 0.08169718316687892\n",
      "Epoch 25/25, Loss: 0.07655350500419736\n",
      "Accuracy: 98.17%, F1 Score: 0.98\n",
      "Training with LR=0.01, Batch Size=32, Optimizer=RMSprop\n",
      "Epoch 1/25, Loss: 0.7447734151244163\n",
      "Epoch 2/25, Loss: 0.3893298042446375\n",
      "Epoch 3/25, Loss: 0.362804330671827\n",
      "Epoch 4/25, Loss: 0.34805097807819646\n",
      "Epoch 5/25, Loss: 0.3388963254918655\n",
      "Epoch 6/25, Loss: 0.34869889034281176\n",
      "Epoch 7/25, Loss: 0.34637860856465996\n",
      "Epoch 8/25, Loss: 0.33927703773751855\n",
      "Epoch 9/25, Loss: 0.3610466196260105\n",
      "Epoch 10/25, Loss: 0.370337391008685\n",
      "Epoch 11/25, Loss: 0.3759091149558624\n",
      "Epoch 12/25, Loss: 0.4075203649736941\n",
      "Epoch 13/25, Loss: 0.4063188425888618\n",
      "Epoch 14/25, Loss: 0.4142380331337452\n",
      "Epoch 15/25, Loss: 0.4399535265808925\n",
      "Epoch 16/25, Loss: 0.40609338940692447\n",
      "Epoch 17/25, Loss: 0.44776661459269623\n",
      "Epoch 18/25, Loss: 0.47583645970001814\n",
      "Epoch 19/25, Loss: 0.49576193361406523\n",
      "Epoch 20/25, Loss: 0.47352523124366996\n",
      "Epoch 21/25, Loss: 0.4629646721805135\n",
      "Epoch 22/25, Loss: 0.467250103234748\n",
      "Epoch 23/25, Loss: 0.5589702172245831\n",
      "Epoch 24/25, Loss: 0.46844144425019624\n",
      "Epoch 25/25, Loss: 0.4944874243206034\n",
      "Accuracy: 95.57%, F1 Score: 0.96\n",
      "Training with LR=0.01, Batch Size=64, Optimizer=Adam\n",
      "Epoch 1/25, Loss: 0.43739609668916984\n",
      "Epoch 2/25, Loss: 0.26394997453932634\n",
      "Epoch 3/25, Loss: 0.24281496762721014\n",
      "Epoch 4/25, Loss: 0.2291825783452881\n",
      "Epoch 5/25, Loss: 0.22653016021082015\n",
      "Epoch 6/25, Loss: 0.22624664109196269\n",
      "Epoch 7/25, Loss: 0.21418852659005885\n",
      "Epoch 8/25, Loss: 0.21369211145861347\n",
      "Epoch 9/25, Loss: 0.20769912308292476\n",
      "Epoch 10/25, Loss: 0.21350485128837068\n",
      "Epoch 11/25, Loss: 0.20766895951063774\n",
      "Epoch 12/25, Loss: 0.19895077782915407\n",
      "Epoch 13/25, Loss: 0.20721705213610106\n",
      "Epoch 14/25, Loss: 0.21305810890372978\n",
      "Epoch 15/25, Loss: 0.1981173071221931\n",
      "Epoch 16/25, Loss: 0.1955575556826911\n",
      "Epoch 17/25, Loss: 0.1985771264995077\n",
      "Epoch 18/25, Loss: 0.1958636609283385\n",
      "Epoch 19/25, Loss: 0.19062190841553783\n",
      "Epoch 20/25, Loss: 0.1954957414686537\n",
      "Epoch 21/25, Loss: 0.1964454696184076\n",
      "Epoch 22/25, Loss: 0.20349194284186942\n",
      "Epoch 23/25, Loss: 0.19857742393693165\n",
      "Epoch 24/25, Loss: 0.19838361584319314\n",
      "Epoch 25/25, Loss: 0.19673389763331045\n",
      "Accuracy: 97.47%, F1 Score: 0.97\n",
      "Training with LR=0.01, Batch Size=64, Optimizer=SGD\n",
      "Epoch 1/25, Loss: 2.187218798757362\n",
      "Epoch 2/25, Loss: 0.9392878332816715\n",
      "Epoch 3/25, Loss: 0.5684662967570809\n",
      "Epoch 4/25, Loss: 0.41792926613265263\n",
      "Epoch 5/25, Loss: 0.3382115271220456\n",
      "Epoch 6/25, Loss: 0.2854853389002303\n",
      "Epoch 7/25, Loss: 0.2547023633062077\n",
      "Epoch 8/25, Loss: 0.2308878052368093\n",
      "Epoch 9/25, Loss: 0.21141365019163724\n",
      "Epoch 10/25, Loss: 0.1938463292523488\n",
      "Epoch 11/25, Loss: 0.1859870273262453\n",
      "Epoch 12/25, Loss: 0.17151964652632026\n",
      "Epoch 13/25, Loss: 0.16499360263554144\n",
      "Epoch 14/25, Loss: 0.15743312274993482\n",
      "Epoch 15/25, Loss: 0.15251599477012273\n",
      "Epoch 16/25, Loss: 0.14354466990248035\n",
      "Epoch 17/25, Loss: 0.14005845612578238\n",
      "Epoch 18/25, Loss: 0.13465925702439951\n",
      "Epoch 19/25, Loss: 0.12929914229567338\n",
      "Epoch 20/25, Loss: 0.12512247123296805\n",
      "Epoch 21/25, Loss: 0.12369790350073087\n",
      "Epoch 22/25, Loss: 0.11730090798690979\n",
      "Epoch 23/25, Loss: 0.11879963359124324\n",
      "Epoch 24/25, Loss: 0.11037514078170696\n",
      "Epoch 25/25, Loss: 0.11328296189301654\n",
      "Accuracy: 97.50%, F1 Score: 0.97\n",
      "Training with LR=0.01, Batch Size=64, Optimizer=RMSprop\n",
      "Epoch 1/25, Loss: 1.3664192980143435\n",
      "Epoch 2/25, Loss: 0.33790177736343985\n",
      "Epoch 3/25, Loss: 0.2947022122090686\n",
      "Epoch 4/25, Loss: 0.27391888345998805\n",
      "Epoch 5/25, Loss: 0.2740780170093467\n",
      "Epoch 6/25, Loss: 0.26291031592777736\n",
      "Epoch 7/25, Loss: 0.2559438588888025\n",
      "Epoch 8/25, Loss: 0.2497222176296259\n",
      "Epoch 9/25, Loss: 0.24341348910442134\n",
      "Epoch 10/25, Loss: 0.24155140133785097\n",
      "Epoch 11/25, Loss: 0.23866034908962847\n",
      "Epoch 12/25, Loss: 0.2533545091853483\n",
      "Epoch 13/25, Loss: 0.24778325816959954\n",
      "Epoch 14/25, Loss: 0.2392144075898664\n",
      "Epoch 15/25, Loss: 0.24012611237173873\n",
      "Epoch 16/25, Loss: 0.23962066893868927\n",
      "Epoch 17/25, Loss: 0.23791844468079268\n",
      "Epoch 18/25, Loss: 0.25566882429334686\n",
      "Epoch 19/25, Loss: 0.23735404291303394\n",
      "Epoch 20/25, Loss: 0.23865640498717616\n",
      "Epoch 21/25, Loss: 0.25096982586553007\n",
      "Epoch 22/25, Loss: 0.2867763223869206\n",
      "Epoch 23/25, Loss: 0.26031191238680723\n",
      "Epoch 24/25, Loss: 0.25263818407576205\n",
      "Epoch 25/25, Loss: 0.2481408489030053\n",
      "Accuracy: 97.11%, F1 Score: 0.97\n",
      "Training with LR=0.01, Batch Size=128, Optimizer=Adam\n",
      "Epoch 1/25, Loss: 0.4802505625272865\n",
      "Epoch 2/25, Loss: 0.2309835036950452\n",
      "Epoch 3/25, Loss: 0.2037718663893656\n",
      "Epoch 4/25, Loss: 0.19146467379129517\n",
      "Epoch 5/25, Loss: 0.19320945756267638\n",
      "Epoch 6/25, Loss: 0.1799327469011868\n",
      "Epoch 7/25, Loss: 0.17835406741417292\n",
      "Epoch 8/25, Loss: 0.17213803342283407\n",
      "Epoch 9/25, Loss: 0.16903119670874528\n",
      "Epoch 10/25, Loss: 0.17437069282046894\n",
      "Epoch 11/25, Loss: 0.17164465975659743\n",
      "Epoch 12/25, Loss: 0.1713247960373791\n",
      "Epoch 13/25, Loss: 0.16357275866257992\n",
      "Epoch 14/25, Loss: 0.16895725029204955\n",
      "Epoch 15/25, Loss: 0.16466497570705185\n",
      "Epoch 16/25, Loss: 0.16064133866429964\n",
      "Epoch 17/25, Loss: 0.15770730290855808\n",
      "Epoch 18/25, Loss: 0.16301070544908422\n",
      "Epoch 19/25, Loss: 0.15880848941550071\n",
      "Epoch 20/25, Loss: 0.16329706456265977\n",
      "Epoch 21/25, Loss: 0.157851598994024\n",
      "Epoch 22/25, Loss: 0.1564459548766679\n",
      "Epoch 23/25, Loss: 0.16053346086190198\n",
      "Epoch 24/25, Loss: 0.15125966987518996\n",
      "Epoch 25/25, Loss: 0.15573508443354545\n",
      "Accuracy: 97.71%, F1 Score: 0.98\n",
      "Training with LR=0.01, Batch Size=128, Optimizer=SGD\n",
      "Epoch 1/25, Loss: 2.2984424374505146\n",
      "Epoch 2/25, Loss: 2.259103709954951\n",
      "Epoch 3/25, Loss: 1.5864650542293783\n",
      "Epoch 4/25, Loss: 0.9069907214087464\n",
      "Epoch 5/25, Loss: 0.7147153119034351\n",
      "Epoch 6/25, Loss: 0.5844026850357747\n",
      "Epoch 7/25, Loss: 0.4965552664768975\n",
      "Epoch 8/25, Loss: 0.43166513858573524\n",
      "Epoch 9/25, Loss: 0.3738424952731712\n",
      "Epoch 10/25, Loss: 0.332103524126732\n",
      "Epoch 11/25, Loss: 0.30410871281425583\n",
      "Epoch 12/25, Loss: 0.27790432342334087\n",
      "Epoch 13/25, Loss: 0.25950846298417046\n",
      "Epoch 14/25, Loss: 0.24392403139552074\n",
      "Epoch 15/25, Loss: 0.22948122486821623\n",
      "Epoch 16/25, Loss: 0.21703640018889644\n",
      "Epoch 17/25, Loss: 0.20378912899539922\n",
      "Epoch 18/25, Loss: 0.19756454243652347\n",
      "Epoch 19/25, Loss: 0.18592253543420642\n",
      "Epoch 20/25, Loss: 0.1776983848989391\n",
      "Epoch 21/25, Loss: 0.17211154953185429\n",
      "Epoch 22/25, Loss: 0.1681870683106278\n",
      "Epoch 23/25, Loss: 0.16054401252029546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Loss: 0.158036047493471\n",
      "Epoch 25/25, Loss: 0.14758261135900452\n",
      "Accuracy: 97.31%, F1 Score: 0.97\n",
      "Training with LR=0.01, Batch Size=128, Optimizer=RMSprop\n",
      "Epoch 1/25, Loss: 1.8132115495738699\n",
      "Epoch 2/25, Loss: 0.8735669227297118\n",
      "Epoch 3/25, Loss: 0.7700469423331686\n",
      "Epoch 4/25, Loss: 0.7144869037274358\n",
      "Epoch 5/25, Loss: 0.6760384763863041\n",
      "Epoch 6/25, Loss: 0.65965937538696\n",
      "Epoch 7/25, Loss: 0.6066192260810307\n",
      "Epoch 8/25, Loss: 0.47522686882568066\n",
      "Epoch 9/25, Loss: 0.4126398598969872\n",
      "Epoch 10/25, Loss: 0.3883197374308287\n",
      "Epoch 11/25, Loss: 0.3626853012835293\n",
      "Epoch 12/25, Loss: 0.3550148580247151\n",
      "Epoch 13/25, Loss: 0.3421150600509857\n",
      "Epoch 14/25, Loss: 0.3289591173119128\n",
      "Epoch 15/25, Loss: 0.3347303142933957\n",
      "Epoch 16/25, Loss: 0.323472504152545\n",
      "Epoch 17/25, Loss: 0.31485034662014894\n",
      "Epoch 18/25, Loss: 0.31873028067701153\n",
      "Epoch 19/25, Loss: 0.31190337288354253\n",
      "Epoch 20/25, Loss: 0.3106046061811925\n",
      "Epoch 21/25, Loss: 0.31033643646471537\n",
      "Epoch 22/25, Loss: 0.29696985486664496\n",
      "Epoch 23/25, Loss: 0.2996639877653071\n",
      "Epoch 24/25, Loss: 0.3027247702802168\n",
      "Epoch 25/25, Loss: 0.2947272593373937\n",
      "Accuracy: 95.10%, F1 Score: 0.95\n",
      "Training with LR=0.001, Batch Size=32, Optimizer=Adam\n",
      "Epoch 1/25, Loss: 0.4856783816109101\n",
      "Epoch 2/25, Loss: 0.19596482327828804\n",
      "Epoch 3/25, Loss: 0.15576261315867304\n",
      "Epoch 4/25, Loss: 0.13341661611013114\n",
      "Epoch 5/25, Loss: 0.12191919903680683\n",
      "Epoch 6/25, Loss: 0.11326200832873583\n",
      "Epoch 7/25, Loss: 0.10450751299131662\n",
      "Epoch 8/25, Loss: 0.09890388569726298\n",
      "Epoch 9/25, Loss: 0.09600265029765044\n",
      "Epoch 10/25, Loss: 0.09358838475264299\n",
      "Epoch 11/25, Loss: 0.0907413758160236\n",
      "Epoch 12/25, Loss: 0.08535863506191721\n",
      "Epoch 13/25, Loss: 0.08435714110710348\n",
      "Epoch 14/25, Loss: 0.08322515233177692\n",
      "Epoch 15/25, Loss: 0.08162209855966891\n",
      "Epoch 16/25, Loss: 0.07924065884271016\n",
      "Epoch 17/25, Loss: 0.0775314593616873\n",
      "Epoch 18/25, Loss: 0.07612356671059194\n",
      "Epoch 19/25, Loss: 0.07696154734219114\n",
      "Epoch 20/25, Loss: 0.07456130073719347\n",
      "Epoch 21/25, Loss: 0.07453404864726278\n",
      "Epoch 22/25, Loss: 0.07338306975535427\n",
      "Epoch 23/25, Loss: 0.07138548126737587\n",
      "Epoch 24/25, Loss: 0.07022295964453369\n",
      "Epoch 25/25, Loss: 0.07313331990465521\n",
      "Accuracy: 98.59%, F1 Score: 0.99\n",
      "Training with LR=0.001, Batch Size=32, Optimizer=SGD\n",
      "Epoch 1/25, Loss: 2.3029329981486004\n",
      "Epoch 2/25, Loss: 2.298422675450643\n",
      "Epoch 3/25, Loss: 2.2919552351633707\n",
      "Epoch 4/25, Loss: 2.2795884059906006\n",
      "Epoch 5/25, Loss: 2.2445009470621744\n",
      "Epoch 6/25, Loss: 2.075513259315491\n",
      "Epoch 7/25, Loss: 1.6075216672261556\n",
      "Epoch 8/25, Loss: 1.2692688535372416\n",
      "Epoch 9/25, Loss: 1.0388400499661763\n",
      "Epoch 10/25, Loss: 0.9211441678682963\n",
      "Epoch 11/25, Loss: 0.832518415927887\n",
      "Epoch 12/25, Loss: 0.7615289645353953\n",
      "Epoch 13/25, Loss: 0.6869325697342554\n",
      "Epoch 14/25, Loss: 0.6287670008420945\n",
      "Epoch 15/25, Loss: 0.5903947869141897\n",
      "Epoch 16/25, Loss: 0.5465971658229828\n",
      "Epoch 17/25, Loss: 0.5113891308069229\n",
      "Epoch 18/25, Loss: 0.4806280699928602\n",
      "Epoch 19/25, Loss: 0.4489439034461975\n",
      "Epoch 20/25, Loss: 0.4259538961966832\n",
      "Epoch 21/25, Loss: 0.4066942440589269\n",
      "Epoch 22/25, Loss: 0.38429658584992094\n",
      "Epoch 23/25, Loss: 0.3690831515351931\n",
      "Epoch 24/25, Loss: 0.3553158543785413\n",
      "Epoch 25/25, Loss: 0.34463772294521333\n",
      "Accuracy: 94.00%, F1 Score: 0.94\n",
      "Training with LR=0.001, Batch Size=32, Optimizer=RMSprop\n",
      "Epoch 1/25, Loss: 0.4757870520273844\n",
      "Epoch 2/25, Loss: 0.19684306353380282\n",
      "Epoch 3/25, Loss: 0.151263934605817\n",
      "Epoch 4/25, Loss: 0.12921048112375041\n",
      "Epoch 5/25, Loss: 0.1198810362891915\n",
      "Epoch 6/25, Loss: 0.11185241290517152\n",
      "Epoch 7/25, Loss: 0.10779335708469152\n",
      "Epoch 8/25, Loss: 0.09769834823201722\n",
      "Epoch 9/25, Loss: 0.09448338116751984\n",
      "Epoch 10/25, Loss: 0.09636847841146713\n",
      "Epoch 11/25, Loss: 0.09083005893453956\n",
      "Epoch 12/25, Loss: 0.08852756882566803\n",
      "Epoch 13/25, Loss: 0.08759942839491802\n",
      "Epoch 14/25, Loss: 0.08481530275400728\n",
      "Epoch 15/25, Loss: 0.08371113335918635\n",
      "Epoch 16/25, Loss: 0.0831828612273559\n",
      "Epoch 17/25, Loss: 0.08292049602360155\n",
      "Epoch 18/25, Loss: 0.08059725436360266\n",
      "Epoch 19/25, Loss: 0.08164267370793968\n",
      "Epoch 20/25, Loss: 0.07840456581584489\n",
      "Epoch 21/25, Loss: 0.07757729804454526\n",
      "Epoch 22/25, Loss: 0.07961402661208995\n",
      "Epoch 23/25, Loss: 0.07882462284644134\n",
      "Epoch 24/25, Loss: 0.07594208261358242\n",
      "Epoch 25/25, Loss: 0.07648278992033253\n",
      "Accuracy: 98.26%, F1 Score: 0.98\n",
      "Training with LR=0.001, Batch Size=64, Optimizer=Adam\n",
      "Epoch 1/25, Loss: 0.6180421008722488\n",
      "Epoch 2/25, Loss: 0.23777474039224292\n",
      "Epoch 3/25, Loss: 0.17623070887784395\n",
      "Epoch 4/25, Loss: 0.1492949143629958\n",
      "Epoch 5/25, Loss: 0.13416762703827131\n",
      "Epoch 6/25, Loss: 0.12092493544630548\n",
      "Epoch 7/25, Loss: 0.11526204832791806\n",
      "Epoch 8/25, Loss: 0.10676491788989588\n",
      "Epoch 9/25, Loss: 0.10289838177803308\n",
      "Epoch 10/25, Loss: 0.09923778399467659\n",
      "Epoch 11/25, Loss: 0.09397798759722785\n",
      "Epoch 12/25, Loss: 0.09234167933751986\n",
      "Epoch 13/25, Loss: 0.08636704821790904\n",
      "Epoch 14/25, Loss: 0.08738826016144854\n",
      "Epoch 15/25, Loss: 0.08297887702310172\n",
      "Epoch 16/25, Loss: 0.08190952652845897\n",
      "Epoch 17/25, Loss: 0.07909794656166644\n",
      "Epoch 18/25, Loss: 0.07781806457658677\n",
      "Epoch 19/25, Loss: 0.0745495451243916\n",
      "Epoch 20/25, Loss: 0.07348728883387978\n",
      "Epoch 21/25, Loss: 0.07234763029130248\n",
      "Epoch 22/25, Loss: 0.07218595082436734\n",
      "Epoch 23/25, Loss: 0.07026826334756806\n",
      "Epoch 24/25, Loss: 0.0714795947570586\n",
      "Epoch 25/25, Loss: 0.06725372790348039\n",
      "Accuracy: 98.62%, F1 Score: 0.99\n",
      "Training with LR=0.001, Batch Size=64, Optimizer=SGD\n",
      "Epoch 1/25, Loss: 2.30237559850282\n",
      "Epoch 2/25, Loss: 2.3002316829746468\n",
      "Epoch 3/25, Loss: 2.2980766466685703\n",
      "Epoch 4/25, Loss: 2.295450268777957\n",
      "Epoch 5/25, Loss: 2.292331541016666\n",
      "Epoch 6/25, Loss: 2.288037455158193\n",
      "Epoch 7/25, Loss: 2.281867942830393\n",
      "Epoch 8/25, Loss: 2.271618057924039\n",
      "Epoch 9/25, Loss: 2.251883323258683\n",
      "Epoch 10/25, Loss: 2.2074996372784126\n",
      "Epoch 11/25, Loss: 2.0894517692675723\n",
      "Epoch 12/25, Loss: 1.8068655914843463\n",
      "Epoch 13/25, Loss: 1.373622920467401\n",
      "Epoch 14/25, Loss: 1.1105022992787839\n",
      "Epoch 15/25, Loss: 1.0005367809394274\n",
      "Epoch 16/25, Loss: 0.9288484334691501\n",
      "Epoch 17/25, Loss: 0.8832024049275974\n",
      "Epoch 18/25, Loss: 0.8437025831071044\n",
      "Epoch 19/25, Loss: 0.8040315720763034\n",
      "Epoch 20/25, Loss: 0.7624129775935399\n",
      "Epoch 21/25, Loss: 0.7297463721430886\n",
      "Epoch 22/25, Loss: 0.7025319144987603\n",
      "Epoch 23/25, Loss: 0.6682457318946496\n",
      "Epoch 24/25, Loss: 0.6382532195686531\n",
      "Epoch 25/25, Loss: 0.6060736878022456\n",
      "Accuracy: 88.69%, F1 Score: 0.89\n",
      "Training with LR=0.001, Batch Size=64, Optimizer=RMSprop\n",
      "Epoch 1/25, Loss: 0.4934882328057213\n",
      "Epoch 2/25, Loss: 0.20815717491672744\n",
      "Epoch 3/25, Loss: 0.15733982735613325\n",
      "Epoch 4/25, Loss: 0.13568014519781604\n",
      "Epoch 5/25, Loss: 0.12441125289519141\n",
      "Epoch 6/25, Loss: 0.11219467862801098\n",
      "Epoch 7/25, Loss: 0.10514641465839626\n",
      "Epoch 8/25, Loss: 0.09854018206009145\n",
      "Epoch 9/25, Loss: 0.09417154500707746\n",
      "Epoch 10/25, Loss: 0.0903934534129772\n",
      "Epoch 11/25, Loss: 0.0876137032307613\n",
      "Epoch 12/25, Loss: 0.08763116510631616\n",
      "Epoch 13/25, Loss: 0.0841019724950945\n",
      "Epoch 14/25, Loss: 0.08225536268742592\n",
      "Epoch 15/25, Loss: 0.07962000331079869\n",
      "Epoch 16/25, Loss: 0.07674546831367866\n",
      "Epoch 17/25, Loss: 0.07618351522455814\n",
      "Epoch 18/25, Loss: 0.07420976096411734\n",
      "Epoch 19/25, Loss: 0.07331136238799968\n",
      "Epoch 20/25, Loss: 0.07202695979503915\n",
      "Epoch 21/25, Loss: 0.07413449686498189\n",
      "Epoch 22/25, Loss: 0.07043543664206352\n",
      "Epoch 23/25, Loss: 0.06967223792320498\n",
      "Epoch 24/25, Loss: 0.06949314927056269\n",
      "Epoch 25/25, Loss: 0.06669860679124083\n",
      "Accuracy: 98.57%, F1 Score: 0.99\n",
      "Training with LR=0.001, Batch Size=128, Optimizer=Adam\n",
      "Epoch 1/25, Loss: 0.7615738692822487\n",
      "Epoch 2/25, Loss: 0.2986837731781545\n",
      "Epoch 3/25, Loss: 0.20975539693509593\n",
      "Epoch 4/25, Loss: 0.1711570523790459\n",
      "Epoch 5/25, Loss: 0.14661825538031073\n",
      "Epoch 6/25, Loss: 0.1305673105805032\n",
      "Epoch 7/25, Loss: 0.12100391525989657\n",
      "Epoch 8/25, Loss: 0.11370372295236664\n",
      "Epoch 9/25, Loss: 0.10853603410361799\n",
      "Epoch 10/25, Loss: 0.09885304117960526\n",
      "Epoch 11/25, Loss: 0.09850336767748984\n",
      "Epoch 12/25, Loss: 0.09317109978863045\n",
      "Epoch 13/25, Loss: 0.09026738079880346\n",
      "Epoch 14/25, Loss: 0.08658327461123022\n",
      "Epoch 15/25, Loss: 0.0853146786835275\n",
      "Epoch 16/25, Loss: 0.08245595586873385\n",
      "Epoch 17/25, Loss: 0.07778205626658094\n",
      "Epoch 18/25, Loss: 0.07918676596953035\n",
      "Epoch 19/25, Loss: 0.07691570150175456\n",
      "Epoch 20/25, Loss: 0.0761890652438582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Loss: 0.07510646884994847\n",
      "Epoch 22/25, Loss: 0.07238130100063488\n",
      "Epoch 23/25, Loss: 0.07104277156039214\n",
      "Epoch 24/25, Loss: 0.06822486075439624\n",
      "Epoch 25/25, Loss: 0.06791355115160949\n",
      "Accuracy: 98.48%, F1 Score: 0.98\n",
      "Training with LR=0.001, Batch Size=128, Optimizer=SGD\n",
      "Epoch 1/25, Loss: 2.302672129450068\n",
      "Epoch 2/25, Loss: 2.301206218662547\n",
      "Epoch 3/25, Loss: 2.2997813524722037\n",
      "Epoch 4/25, Loss: 2.2984112874785465\n",
      "Epoch 5/25, Loss: 2.296954906825572\n",
      "Epoch 6/25, Loss: 2.2954824128384783\n",
      "Epoch 7/25, Loss: 2.293757662335947\n",
      "Epoch 8/25, Loss: 2.2917933636891052\n",
      "Epoch 9/25, Loss: 2.2896258841191273\n",
      "Epoch 10/25, Loss: 2.2868151029289914\n",
      "Epoch 11/25, Loss: 2.2833589185783856\n",
      "Epoch 12/25, Loss: 2.2791449967732054\n",
      "Epoch 13/25, Loss: 2.273430465889384\n",
      "Epoch 14/25, Loss: 2.2660256296332713\n",
      "Epoch 15/25, Loss: 2.2556272869679463\n",
      "Epoch 16/25, Loss: 2.24092428770655\n",
      "Epoch 17/25, Loss: 2.217526837960998\n",
      "Epoch 18/25, Loss: 2.18051575445163\n",
      "Epoch 19/25, Loss: 2.1157435420225426\n",
      "Epoch 20/25, Loss: 2.0039820973552875\n",
      "Epoch 21/25, Loss: 1.8317057483994377\n",
      "Epoch 22/25, Loss: 1.5969180262673384\n",
      "Epoch 23/25, Loss: 1.3550270381512672\n",
      "Epoch 24/25, Loss: 1.1857972584807797\n",
      "Epoch 25/25, Loss: 1.087945193370014\n",
      "Accuracy: 73.93%, F1 Score: 0.72\n",
      "Training with LR=0.001, Batch Size=128, Optimizer=RMSprop\n",
      "Epoch 1/25, Loss: 0.5668900259839955\n",
      "Epoch 2/25, Loss: 0.23902929364554665\n",
      "Epoch 3/25, Loss: 0.17151652745950197\n",
      "Epoch 4/25, Loss: 0.14175287143253823\n",
      "Epoch 5/25, Loss: 0.12761142255782065\n",
      "Epoch 6/25, Loss: 0.1164132029707752\n",
      "Epoch 7/25, Loss: 0.10880608281799789\n",
      "Epoch 8/25, Loss: 0.09995708234512857\n",
      "Epoch 9/25, Loss: 0.09672148504070063\n",
      "Epoch 10/25, Loss: 0.09346248003751484\n",
      "Epoch 11/25, Loss: 0.09043757239185861\n",
      "Epoch 12/25, Loss: 0.08504691127854497\n",
      "Epoch 13/25, Loss: 0.08317783208234288\n",
      "Epoch 14/25, Loss: 0.07984439918854788\n",
      "Epoch 15/25, Loss: 0.07945581930659727\n",
      "Epoch 16/25, Loss: 0.07526261255299962\n",
      "Epoch 17/25, Loss: 0.07380261313893012\n",
      "Epoch 18/25, Loss: 0.07257500570267439\n",
      "Epoch 19/25, Loss: 0.073016556572598\n",
      "Epoch 20/25, Loss: 0.06948750070097652\n",
      "Epoch 21/25, Loss: 0.06911339151408913\n",
      "Epoch 22/25, Loss: 0.0680359538211656\n",
      "Epoch 23/25, Loss: 0.06866813521645566\n",
      "Epoch 24/25, Loss: 0.06617839023697256\n",
      "Epoch 25/25, Loss: 0.0664207054756836\n",
      "Accuracy: 98.09%, F1 Score: 0.98\n",
      "Training with LR=0.0001, Batch Size=32, Optimizer=Adam\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e20862166782>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLeNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'f1_score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e20862166782>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_loader, test_loader, lr, batch_size, optimizer_type)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1560\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontrast_factor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjust_contrast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrast_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m             \u001b[1;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msaturation_factor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjust_saturation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhue_factor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to Train and Evaluate with Hyperparameter Logging\n",
    "def train_and_evaluate(model, train_loader, test_loader, lr, batch_size, optimizer_type):\n",
    "    print(f\"Training with LR={lr}, Batch Size={batch_size}, Optimizer={optimizer_type.__name__}\")\n",
    "    \n",
    "    # Reinitialize Model\n",
    "    model = LeNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optimizer_type(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = sum([1 for true, pred in zip(all_labels, all_preds) if true == pred]) / len(all_labels)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%, F1 Score: {f1:.2f}\")\n",
    "    return accuracy, f1\n",
    "\n",
    "# Hyperparameter Tuning Loop\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "optimizers = [optim.Adam, optim.SGD, optim.RMSprop]\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for opt in optimizers:\n",
    "            # Update DataLoader for Batch Size\n",
    "            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            acc, f1 = train_and_evaluate(LeNet(), train_loader, test_loader, lr, batch_size, opt)\n",
    "            results.append({'lr': lr, 'batch_size': batch_size, 'optimizer': opt.__name__, 'accuracy': acc, 'f1_score': f1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c17c38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Performances:\n",
      "{'lr': 0.001, 'batch_size': 64, 'optimizer': 'RMSprop', 'accuracy': 0.9911, 'f1_score': 0.9910972658442102}\n",
      "{'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adam', 'accuracy': 0.991, 'f1_score': 0.9909983860845659}\n",
      "{'lr': 0.001, 'batch_size': 64, 'optimizer': 'Adam', 'accuracy': 0.9903, 'f1_score': 0.9903058128715826}\n",
      "{'lr': 0.001, 'batch_size': 128, 'optimizer': 'RMSprop', 'accuracy': 0.9898, 'f1_score': 0.9898013697216468}\n",
      "{'lr': 0.0001, 'batch_size': 64, 'optimizer': 'RMSprop', 'accuracy': 0.9895, 'f1_score': 0.9894985491587075}\n",
      "{'lr': 0.01, 'batch_size': 32, 'optimizer': 'SGD', 'accuracy': 0.9886, 'f1_score': 0.9885963798807932}\n",
      "{'lr': 0.0001, 'batch_size': 32, 'optimizer': 'RMSprop', 'accuracy': 0.9885, 'f1_score': 0.988504158512488}\n",
      "{'lr': 0.0001, 'batch_size': 64, 'optimizer': 'Adam', 'accuracy': 0.9882, 'f1_score': 0.988194569538461}\n",
      "{'lr': 0.001, 'batch_size': 32, 'optimizer': 'RMSprop', 'accuracy': 0.9878, 'f1_score': 0.9878017757449852}\n",
      "{'lr': 0.001, 'batch_size': 128, 'optimizer': 'Adam', 'accuracy': 0.9878, 'f1_score': 0.9877970627563117}\n",
      "{'lr': 0.0001, 'batch_size': 32, 'optimizer': 'Adam', 'accuracy': 0.9874, 'f1_score': 0.9873978332113762}\n",
      "{'lr': 0.0001, 'batch_size': 128, 'optimizer': 'RMSprop', 'accuracy': 0.9874, 'f1_score': 0.9873922198904945}\n",
      "{'lr': 0.01, 'batch_size': 64, 'optimizer': 'SGD', 'accuracy': 0.9872, 'f1_score': 0.9871919159260074}\n",
      "{'lr': 0.01, 'batch_size': 128, 'optimizer': 'RMSprop', 'accuracy': 0.9863, 'f1_score': 0.986333081739178}\n",
      "{'lr': 0.0001, 'batch_size': 128, 'optimizer': 'Adam', 'accuracy': 0.9845, 'f1_score': 0.9845049382809593}\n",
      "{'lr': 0.01, 'batch_size': 64, 'optimizer': 'Adam', 'accuracy': 0.9826, 'f1_score': 0.982702871757195}\n",
      "{'lr': 0.01, 'batch_size': 128, 'optimizer': 'Adam', 'accuracy': 0.981, 'f1_score': 0.980986797263065}\n",
      "{'lr': 0.01, 'batch_size': 128, 'optimizer': 'SGD', 'accuracy': 0.9807, 'f1_score': 0.9807297989783276}\n",
      "{'lr': 0.01, 'batch_size': 64, 'optimizer': 'RMSprop', 'accuracy': 0.9794, 'f1_score': 0.9794544781367537}\n",
      "{'lr': 0.001, 'batch_size': 32, 'optimizer': 'SGD', 'accuracy': 0.9768, 'f1_score': 0.9767704704487056}\n",
      "{'lr': 0.01, 'batch_size': 32, 'optimizer': 'Adam', 'accuracy': 0.962, 'f1_score': 0.9624740620828115}\n",
      "{'lr': 0.001, 'batch_size': 64, 'optimizer': 'SGD', 'accuracy': 0.9476, 'f1_score': 0.9474958873048374}\n",
      "{'lr': 0.001, 'batch_size': 128, 'optimizer': 'SGD', 'accuracy': 0.9171, 'f1_score': 0.9168642255147813}\n",
      "{'lr': 0.01, 'batch_size': 32, 'optimizer': 'RMSprop', 'accuracy': 0.8651, 'f1_score': 0.8605440792940643}\n",
      "{'lr': 0.0001, 'batch_size': 32, 'optimizer': 'SGD', 'accuracy': 0.4403, 'f1_score': 0.3634845417238615}\n",
      "{'lr': 0.0001, 'batch_size': 128, 'optimizer': 'SGD', 'accuracy': 0.1427, 'f1_score': 0.06164631351618396}\n",
      "{'lr': 0.0001, 'batch_size': 64, 'optimizer': 'SGD', 'accuracy': 0.1299, 'f1_score': 0.04947363268355518}\n"
     ]
    }
   ],
   "source": [
    "results = sorted(results, key=lambda x: x['f1_score'], reverse=True)\n",
    "print(\"Top Performances:\")\n",
    "for result in results[:50]:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc07ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with LR=0.001, Batch Size=64, Optimizer=RMSprop\n",
      "Epoch 1/25, Loss: 0.46860229279567944\n",
      "Epoch 2/25, Loss: 0.20873892185157106\n",
      "Epoch 3/25, Loss: 0.16358606952991187\n",
      "Epoch 4/25, Loss: 0.14018172402776827\n",
      "Epoch 5/25, Loss: 0.12541642670742056\n",
      "Epoch 6/25, Loss: 0.11454202352103585\n",
      "Epoch 7/25, Loss: 0.10413099325367256\n",
      "Epoch 8/25, Loss: 0.09989011221414389\n",
      "Epoch 9/25, Loss: 0.09789784025273789\n",
      "Epoch 10/25, Loss: 0.09300048935881405\n",
      "Epoch 11/25, Loss: 0.09003821961598586\n",
      "Epoch 12/25, Loss: 0.08647762525003594\n",
      "Epoch 13/25, Loss: 0.08263417909235589\n",
      "Epoch 14/25, Loss: 0.0822591709212831\n",
      "Epoch 15/25, Loss: 0.081339598181588\n",
      "Epoch 16/25, Loss: 0.07761746563818127\n",
      "Epoch 17/25, Loss: 0.07589666746325417\n",
      "Epoch 18/25, Loss: 0.075303801169335\n",
      "Epoch 19/25, Loss: 0.07493328791348014\n",
      "Epoch 20/25, Loss: 0.07349263487678112\n",
      "Epoch 21/25, Loss: 0.0732378926098859\n",
      "Epoch 22/25, Loss: 0.07171732661955213\n",
      "Epoch 23/25, Loss: 0.0703032289944174\n",
      "Epoch 24/25, Loss: 0.06846904435179142\n",
      "Epoch 25/25, Loss: 0.06851898727621804\n",
      "Accuracy: 98.38%, F1 Score: 0.98\n",
      "Accuracy with Augmentation: 98.38%, F1 Score with Augmentation: 0.98\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Function to Train and Evaluate with Hyperparameter Logging\n",
    "def train_and_evaluate(model, train_loader, test_loader, lr, batch_size, optimizer_type):\n",
    "    print(f\"Training with LR={lr}, Batch Size={batch_size}, Optimizer={optimizer_type.__name__}\")\n",
    "    \n",
    "    # Reinitialize Model\n",
    "    model = LeNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optimizer_type(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = sum([1 for true, pred in zip(all_labels, all_preds) if true == pred]) / len(all_labels)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%, F1 Score: {f1:.2f}\")\n",
    "    return accuracy, f1\n",
    "\n",
    "# Augmentation for Training Data\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),       # Randomly flip horizontally\n",
    "    transforms.RandomRotation(10),           # Random rotation by ±10 degrees\n",
    "    transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),  # Random cropping and scaling\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Adjust brightness and contrast\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))     # Normalize\n",
    "])\n",
    "\n",
    "# Standard Transformation for Test Data\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load Datasets with Transformations\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=train_transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=test_transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Reuse the Model, Training, and Evaluation Functions\n",
    "accuracy, f1 = train_and_evaluate(LeNet(), train_loader, test_loader, lr=0.001, batch_size=64, optimizer_type=optim.RMSprop)\n",
    "\n",
    "print(f\"Accuracy with Augmentation: {accuracy*100:.2f}%, F1 Score with Augmentation: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0670456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Latency per Sample: 0.7271 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# Set Model to Evaluation Mode\n",
    "model.eval()\n",
    "\n",
    "# Create a Single Input Sample (Shape for MNIST: [1, 1, 28, 28])\n",
    "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "\n",
    "# Measure Latency\n",
    "num_iterations = 100\n",
    "latency_times = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_iterations):\n",
    "        start_time = time.time()\n",
    "        _ = model(dummy_input)  # Forward pass\n",
    "        end_time = time.time()\n",
    "        latency_times.append(end_time - start_time)\n",
    "\n",
    "# Calculate Average Latency\n",
    "average_latency = sum(latency_times) / num_iterations\n",
    "print(f\"Average Latency per Sample: {average_latency*1000:.4f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfcadf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f771d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to ONNX format: lenet_model.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Export the model to ONNX format\n",
    "dummy_input = torch.randn(1, 1, 28, 28).to(device)  # Adjust shape for your input\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    \"lenet_model.onnx\", \n",
    "    input_names=[\"input\"], \n",
    "    output_names=[\"output\"], \n",
    "    opset_version=11\n",
    ")\n",
    "print(\"Model exported to ONNX format: lenet_model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9dc0d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.7.0\n"
     ]
    }
   ],
   "source": [
    "print(trt.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d3a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import custom_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    ]\n",
    ")\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(\n",
    "    root=\"../data/dataset\", train=True, transform=train_transform, download=True\n",
    ")\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"../data/dataset\", train=False, transform=test_transform, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100], Loss: 1.5281\n",
      "Epoch: [2/100], Loss: 1.1570\n",
      "Epoch: [3/100], Loss: 1.0103\n",
      "Epoch: [4/100], Loss: 0.9113\n",
      "Epoch: [5/100], Loss: 0.8424\n",
      "Epoch: [6/100], Loss: 0.7853\n",
      "Epoch: [7/100], Loss: 0.7403\n",
      "Epoch: [8/100], Loss: 0.6979\n",
      "Epoch: [9/100], Loss: 0.6611\n",
      "Epoch: [10/100], Loss: 0.6289\n",
      "Epoch: [11/100], Loss: 0.5959\n",
      "Epoch: [12/100], Loss: 0.5646\n",
      "Epoch: [13/100], Loss: 0.5356\n",
      "Epoch: [14/100], Loss: 0.5095\n",
      "Epoch: [15/100], Loss: 0.4813\n",
      "Epoch: [16/100], Loss: 0.4565\n",
      "Epoch: [17/100], Loss: 0.4338\n",
      "Epoch: [18/100], Loss: 0.4105\n",
      "Epoch: [19/100], Loss: 0.3898\n",
      "Epoch: [20/100], Loss: 0.3711\n",
      "Epoch: [21/100], Loss: 0.3499\n",
      "Epoch: [22/100], Loss: 0.3305\n",
      "Epoch: [23/100], Loss: 0.3160\n",
      "Epoch: [24/100], Loss: 0.2949\n",
      "Epoch: [25/100], Loss: 0.2814\n",
      "Epoch: [26/100], Loss: 0.2633\n",
      "Epoch: [27/100], Loss: 0.2495\n",
      "Epoch: [28/100], Loss: 0.2389\n",
      "Epoch: [29/100], Loss: 0.2282\n",
      "Epoch: [30/100], Loss: 0.2202\n",
      "Epoch: [31/100], Loss: 0.2052\n",
      "Epoch: [32/100], Loss: 0.1921\n",
      "Epoch: [33/100], Loss: 0.1850\n",
      "Epoch: [34/100], Loss: 0.1753\n",
      "Epoch: [35/100], Loss: 0.1668\n",
      "Epoch: [36/100], Loss: 0.1583\n",
      "Epoch: [37/100], Loss: 0.1543\n",
      "Epoch: [38/100], Loss: 0.1431\n",
      "Epoch: [39/100], Loss: 0.1410\n",
      "Epoch: [40/100], Loss: 0.1341\n",
      "Epoch: [41/100], Loss: 0.1295\n",
      "Epoch: [42/100], Loss: 0.1233\n",
      "Epoch: [43/100], Loss: 0.1202\n",
      "Epoch: [44/100], Loss: 0.1132\n",
      "Epoch: [45/100], Loss: 0.1119\n",
      "Epoch: [46/100], Loss: 0.1072\n",
      "Epoch: [47/100], Loss: 0.1059\n",
      "Epoch: [48/100], Loss: 0.0984\n",
      "Epoch: [49/100], Loss: 0.0978\n",
      "Epoch: [50/100], Loss: 0.0907\n",
      "Epoch: [51/100], Loss: 0.0920\n",
      "Epoch: [52/100], Loss: 0.0909\n",
      "Epoch: [53/100], Loss: 0.0887\n",
      "Epoch: [54/100], Loss: 0.0847\n",
      "Epoch: [55/100], Loss: 0.0793\n",
      "Epoch: [56/100], Loss: 0.0829\n",
      "Epoch: [57/100], Loss: 0.0802\n",
      "Epoch: [58/100], Loss: 0.0752\n",
      "Epoch: [59/100], Loss: 0.0743\n",
      "Epoch: [60/100], Loss: 0.0733\n",
      "Epoch: [61/100], Loss: 0.0704\n",
      "Epoch: [62/100], Loss: 0.0715\n",
      "Epoch: [63/100], Loss: 0.0691\n",
      "Epoch: [64/100], Loss: 0.0687\n",
      "Epoch: [65/100], Loss: 0.0680\n",
      "Epoch: [66/100], Loss: 0.0639\n",
      "Epoch: [67/100], Loss: 0.0626\n",
      "Epoch: [68/100], Loss: 0.0699\n",
      "Epoch: [69/100], Loss: 0.0636\n",
      "Epoch: [70/100], Loss: 0.0603\n",
      "Epoch: [71/100], Loss: 0.0548\n",
      "Epoch: [72/100], Loss: 0.0600\n",
      "Epoch: [73/100], Loss: 0.0576\n",
      "Epoch: [74/100], Loss: 0.0597\n",
      "Epoch: [75/100], Loss: 0.0592\n",
      "Epoch: [76/100], Loss: 0.0583\n",
      "Epoch: [77/100], Loss: 0.0563\n",
      "Epoch: [78/100], Loss: 0.0580\n",
      "Epoch: [79/100], Loss: 0.0487\n",
      "Epoch: [80/100], Loss: 0.0539\n",
      "Epoch: [81/100], Loss: 0.0553\n",
      "Epoch: [82/100], Loss: 0.0513\n",
      "Epoch: [83/100], Loss: 0.0511\n",
      "Epoch: [84/100], Loss: 0.0535\n",
      "Epoch: [85/100], Loss: 0.0503\n",
      "Epoch: [86/100], Loss: 0.0469\n",
      "Epoch: [87/100], Loss: 0.0489\n",
      "Epoch: [88/100], Loss: 0.0485\n",
      "Epoch: [89/100], Loss: 0.0492\n",
      "Epoch: [90/100], Loss: 0.0448\n",
      "Epoch: [91/100], Loss: 0.0456\n",
      "Epoch: [92/100], Loss: 0.0472\n",
      "Epoch: [93/100], Loss: 0.0481\n",
      "Epoch: [94/100], Loss: 0.0439\n",
      "Epoch: [95/100], Loss: 0.0456\n",
      "Epoch: [96/100], Loss: 0.0450\n",
      "Epoch: [97/100], Loss: 0.0414\n",
      "Epoch: [98/100], Loss: 0.0431\n",
      "Epoch: [99/100], Loss: 0.0433\n",
      "Epoch: [100/100], Loss: 0.0424\n"
     ]
    }
   ],
   "source": [
    "model = custom_cnn.CNNModel()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward propagation\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print loss per epoch\n",
    "    print(\n",
    "        f\"Epoch: [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"trained_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_loader, model, device):\n",
    "    model.to(\"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    total_latency = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            \n",
    "            # Measure latency and CPU usage\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            predicted_labels.extend(predicted.to('cpu').tolist())\n",
    "            true_labels.extend(labels.to('cpu').tolist())\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_latency_per_batch = total_latency / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return accuracy,predicted_labels, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 23.62%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23.62,\n",
       " [3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  6,\n",
       "  3,\n",
       "  6,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  8,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  0,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  6,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  6,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  4,\n",
       "  3,\n",
       "  8,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  2,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  0,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  7,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  6,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  6,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  6,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  ...],\n",
       " [3,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  1,\n",
       "  6,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  9,\n",
       "  8,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  4,\n",
       "  9,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  0,\n",
       "  9,\n",
       "  6,\n",
       "  6,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  9,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  9,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  7,\n",
       "  6,\n",
       "  9,\n",
       "  8,\n",
       "  0,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  7,\n",
       "  4,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  6,\n",
       "  3,\n",
       "  6,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  7,\n",
       "  2,\n",
       "  6,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  2,\n",
       "  9,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  3,\n",
       "  8,\n",
       "  6,\n",
       "  4,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  6,\n",
       "  8,\n",
       "  7,\n",
       "  4,\n",
       "  0,\n",
       "  6,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  7,\n",
       "  8,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  8,\n",
       "  0,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  8,\n",
       "  9,\n",
       "  1,\n",
       "  2,\n",
       "  9,\n",
       "  7,\n",
       "  2,\n",
       "  9,\n",
       "  6,\n",
       "  5,\n",
       "  6,\n",
       "  3,\n",
       "  8,\n",
       "  7,\n",
       "  6,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  8,\n",
       "  9,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  9,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  4,\n",
       "  8,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  3,\n",
       "  7,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  8,\n",
       "  6,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  7,\n",
       "  2,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  8,\n",
       "  5,\n",
       "  1,\n",
       "  8,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  7,\n",
       "  9,\n",
       "  7,\n",
       "  4,\n",
       "  5,\n",
       "  9,\n",
       "  8,\n",
       "  0,\n",
       "  7,\n",
       "  9,\n",
       "  8,\n",
       "  2,\n",
       "  7,\n",
       "  6,\n",
       "  9,\n",
       "  4,\n",
       "  3,\n",
       "  9,\n",
       "  6,\n",
       "  4,\n",
       "  7,\n",
       "  6,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  9,\n",
       "  9,\n",
       "  4,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  9,\n",
       "  8,\n",
       "  1,\n",
       "  5,\n",
       "  7,\n",
       "  0,\n",
       "  8,\n",
       "  2,\n",
       "  4,\n",
       "  7,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  6,\n",
       "  3,\n",
       "  8,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  1,\n",
       "  0,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  7,\n",
       "  9,\n",
       "  1,\n",
       "  2,\n",
       "  6,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  3,\n",
       "  2,\n",
       "  6,\n",
       "  1,\n",
       "  8,\n",
       "  2,\n",
       "  1,\n",
       "  6,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  7,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  6,\n",
       "  6,\n",
       "  9,\n",
       "  3,\n",
       "  8,\n",
       "  0,\n",
       "  7,\n",
       "  2,\n",
       "  6,\n",
       "  2,\n",
       "  5,\n",
       "  8,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  7,\n",
       "  3,\n",
       "  2,\n",
       "  8,\n",
       "  0,\n",
       "  9,\n",
       "  5,\n",
       "  8,\n",
       "  1,\n",
       "  9,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  9,\n",
       "  4,\n",
       "  2,\n",
       "  7,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  9,\n",
       "  0,\n",
       "  9,\n",
       "  2,\n",
       "  8,\n",
       "  7,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  6,\n",
       "  2,\n",
       "  9,\n",
       "  6,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  9,\n",
       "  8,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  8,\n",
       "  2,\n",
       "  7,\n",
       "  9,\n",
       "  3,\n",
       "  6,\n",
       "  1,\n",
       "  9,\n",
       "  0,\n",
       "  7,\n",
       "  3,\n",
       "  7,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  6,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  7,\n",
       "  3,\n",
       "  7,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  9,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  9,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  5,\n",
       "  6,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  3,\n",
       "  7,\n",
       "  8,\n",
       "  3,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  5,\n",
       "  7,\n",
       "  6,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  5,\n",
       "  5,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  4,\n",
       "  6,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  8,\n",
       "  9,\n",
       "  5,\n",
       "  8,\n",
       "  5,\n",
       "  7,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  6,\n",
       "  9,\n",
       "  0,\n",
       "  9,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  2,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  7,\n",
       "  6,\n",
       "  7,\n",
       "  5,\n",
       "  9,\n",
       "  1,\n",
       "  6,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  8,\n",
       "  5,\n",
       "  9,\n",
       "  4,\n",
       "  6,\n",
       "  4,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  7,\n",
       "  6,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  9,\n",
       "  7,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  8,\n",
       "  4,\n",
       "  0,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  8,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  8,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  6,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  5,\n",
       "  8,\n",
       "  6,\n",
       "  6,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  7,\n",
       "  1,\n",
       "  2,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  6,\n",
       "  8,\n",
       "  7,\n",
       "  6,\n",
       "  8,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  7,\n",
       "  9,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  9,\n",
       "  5,\n",
       "  6,\n",
       "  9,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  9,\n",
       "  4,\n",
       "  7,\n",
       "  6,\n",
       "  3,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  6,\n",
       "  3,\n",
       "  6,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  9,\n",
       "  6,\n",
       "  4,\n",
       "  8,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  6,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  7,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  2,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  8,\n",
       "  7,\n",
       "  4,\n",
       "  2,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  8,\n",
       "  8,\n",
       "  1,\n",
       "  8,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  6,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  4,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  7,\n",
       "  0,\n",
       "  7,\n",
       "  9,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  2,\n",
       "  5,\n",
       "  9,\n",
       "  2,\n",
       "  9,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  6,\n",
       "  8,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  7,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  1,\n",
       "  6,\n",
       "  4,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  6,\n",
       "  0,\n",
       "  5,\n",
       "  9,\n",
       "  1,\n",
       "  7,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  3,\n",
       "  9,\n",
       "  6,\n",
       "  8,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  7,\n",
       "  7,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  2,\n",
       "  7,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  4,\n",
       "  4,\n",
       "  8,\n",
       "  4,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  3,\n",
       "  7,\n",
       "  2,\n",
       "  0,\n",
       "  8,\n",
       "  9,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  6,\n",
       "  2,\n",
       "  0,\n",
       "  8,\n",
       "  7,\n",
       "  3,\n",
       "  7,\n",
       "  6,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  9,\n",
       "  2,\n",
       "  7,\n",
       "  0,\n",
       "  7,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  4,\n",
       "  7,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  7,\n",
       "  7,\n",
       "  0,\n",
       "  7,\n",
       "  8,\n",
       "  4,\n",
       "  6,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  8,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  7,\n",
       "  8,\n",
       "  4,\n",
       "  3,\n",
       "  0,\n",
       "  9,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  6,\n",
       "  7,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  7,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  6,\n",
       "  6,\n",
       "  5,\n",
       "  8,\n",
       "  7,\n",
       "  1,\n",
       "  6,\n",
       "  8,\n",
       "  8,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  8,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  7,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  1,\n",
       "  7,\n",
       "  4,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  9,\n",
       "  6,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  0,\n",
       "  3,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  9,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  9,\n",
       "  0,\n",
       "  4,\n",
       "  7,\n",
       "  8,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  8,\n",
       "  4,\n",
       "  6,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  3,\n",
       "  8,\n",
       "  ...])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(test_loader,model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved conv_layers.0.weight to conv2d_kernel_0.bin\n",
      "Saved conv_layers.0.bias to conv2d_bias_0.bin\n",
      "Saved conv_layers.1.weight to batch_normalization_gamma_0.bin\n",
      "Saved conv_layers.1.bias to batch_normalization_beta_0.bin\n",
      "Saved conv_layers.1.running_mean to batch_normalization_moving_mean_0.bin\n",
      "Saved conv_layers.1.running_var to batch_normalization_moving_variance_0.bin\n",
      "Parameter conv_layers.1.num_batches_tracked not mapped to a filename.\n",
      "Saved conv_layers.4.weight to conv2d_1_kernel_0.bin\n",
      "Saved conv_layers.4.bias to conv2d_1_bias_0.bin\n",
      "Saved conv_layers.5.weight to batch_normalization_1_gamma_0.bin\n",
      "Saved conv_layers.5.bias to batch_normalization_1_beta_0.bin\n",
      "Saved conv_layers.5.running_mean to batch_normalization_1_moving_mean_0.bin\n",
      "Saved conv_layers.5.running_var to batch_normalization_1_moving_variance_0.bin\n",
      "Parameter conv_layers.5.num_batches_tracked not mapped to a filename.\n",
      "Saved conv_layers.8.weight to conv2d_2_kernel_0.bin\n",
      "Saved conv_layers.8.bias to conv2d_2_bias_0.bin\n",
      "Saved conv_layers.9.weight to batch_normalization_2_gamma_0.bin\n",
      "Saved conv_layers.9.bias to batch_normalization_2_beta_0.bin\n",
      "Saved conv_layers.9.running_mean to batch_normalization_2_moving_mean_0.bin\n",
      "Saved conv_layers.9.running_var to batch_normalization_2_moving_variance_0.bin\n",
      "Parameter conv_layers.9.num_batches_tracked not mapped to a filename.\n",
      "Parameter fc_layers.1.weight not mapped to a filename.\n",
      "Parameter fc_layers.1.bias not mapped to a filename.\n",
      "Parameter fc_layers.4.weight not mapped to a filename.\n",
      "Parameter fc_layers.4.bias not mapped to a filename.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load your model\n",
    "\n",
    "# Define the mapping from parameter names to filenames\n",
    "param_to_filename = {\n",
    "    'conv_layers.0.weight': 'conv2d_kernel_0.bin',\n",
    "    'conv_layers.0.bias': 'conv2d_bias_0.bin',\n",
    "    'conv_layers.1.weight': 'batch_normalization_gamma_0.bin',\n",
    "    'conv_layers.1.bias': 'batch_normalization_beta_0.bin',\n",
    "    'conv_layers.1.running_mean': 'batch_normalization_moving_mean_0.bin',\n",
    "    'conv_layers.1.running_var': 'batch_normalization_moving_variance_0.bin',\n",
    "\n",
    "    'conv_layers.4.weight': 'conv2d_1_kernel_0.bin',\n",
    "    'conv_layers.4.bias': 'conv2d_1_bias_0.bin',\n",
    "    'conv_layers.5.weight': 'batch_normalization_1_gamma_0.bin',\n",
    "    'conv_layers.5.bias': 'batch_normalization_1_beta_0.bin',\n",
    "    'conv_layers.5.running_mean': 'batch_normalization_1_moving_mean_0.bin',\n",
    "    'conv_layers.5.running_var': 'batch_normalization_1_moving_variance_0.bin',\n",
    "\n",
    "    'conv_layers.8.weight': 'conv2d_2_kernel_0.bin',\n",
    "    'conv_layers.8.bias': 'conv2d_2_bias_0.bin',\n",
    "    'conv_layers.9.weight': 'batch_normalization_2_gamma_0.bin',\n",
    "    'conv_layers.9.bias': 'batch_normalization_2_beta_0.bin',\n",
    "    'conv_layers.9.running_mean': 'batch_normalization_2_moving_mean_0.bin',\n",
    "    'conv_layers.9.running_var': 'batch_normalization_2_moving_variance_0.bin',\n",
    "\n",
    "    'fc_layers.2.weight': 'dense_kernel_0.bin',\n",
    "    'fc_layers.2.bias': 'dense_bias_0.bin',\n",
    "    'fc_layers.3.weight': 'batch_normalization_3_gamma_0.bin',\n",
    "    'fc_layers.3.bias': 'batch_normalization_3_beta_0.bin',\n",
    "    'fc_layers.3.running_mean': 'batch_normalization_3_moving_mean_0.bin',\n",
    "    'fc_layers.3.running_var': 'batch_normalization_3_moving_variance_0.bin',\n",
    "\n",
    "    'fc_layers.6.weight': 'dense_1_kernel_0.bin',\n",
    "    'fc_layers.6.bias': 'dense_1_bias_0.bin',\n",
    "    'fc_layers.7.weight': 'batch_normalization_4_gamma_0.bin',\n",
    "    'fc_layers.7.bias': 'batch_normalization_4_beta_0.bin',\n",
    "    'fc_layers.7.running_mean': 'batch_normalization_4_moving_mean_0.bin',\n",
    "    'fc_layers.7.running_var': 'batch_normalization_4_moving_variance_0.bin',\n",
    "}\n",
    "\n",
    "# Iterate over the model's state_dict and save each parameter\n",
    "for param_name, param_value in model.state_dict().items():\n",
    "    if param_name in param_to_filename:\n",
    "        # Convert the tensor to a NumPy array\n",
    "        param_numpy = param_value.cpu().numpy()\n",
    "        # Save to binary file\n",
    "        param_numpy.tofile(f'../data/weights/{param_to_filename[param_name]}')\n",
    "        print(f\"Saved {param_name} to {param_to_filename[param_name]}\")\n",
    "    else:\n",
    "        print(f\"Parameter {param_name} not mapped to a filename.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All weights and biases dumped successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Dump weights for convolutional layers\n",
    "conv_counter = 1\n",
    "for layer in model.conv_layers:\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        # Save weights\n",
    "        weights = layer.weight.data.cpu().numpy()\n",
    "        weights.tofile(f'conv{conv_counter}_weights.bin')\n",
    "        \n",
    "        # Save biases\n",
    "        biases = layer.bias.data.cpu().numpy()\n",
    "        biases.tofile(f'conv{conv_counter}_biases.bin')\n",
    "        \n",
    "        conv_counter += 1\n",
    "\n",
    "# Dump weights for fully connected layers\n",
    "fc_counter = 1\n",
    "for layer in model.fc_layers:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        # Save weights\n",
    "        weights = layer.weight.data.cpu().numpy()\n",
    "        weights.tofile(f'fc{fc_counter}_weights.bin')\n",
    "        \n",
    "        # Save biases (if they exist)\n",
    "        if layer.bias is not None:\n",
    "            biases = layer.bias.data.cpu().numpy()\n",
    "            biases.tofile(f'fc{fc_counter}_biases.bin')\n",
    "        \n",
    "        fc_counter += 1\n",
    "\n",
    "print(\"All weights and biases dumped successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 11:42:38.856812: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 153600000 exceeds 10% of free system memory.\n",
      "2025-01-30 11:42:42.575621: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "2025-01-30 11:42:48.008098: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 122880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create TensorFlow datasets with explicit dtype\u001b[39;00m\n\u001b[1;32m     34\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(\n\u001b[1;32m     35\u001b[0m     (tf\u001b[38;5;241m.\u001b[39mcast(train_images, tf\u001b[38;5;241m.\u001b[39mfloat32), tf\u001b[38;5;241m.\u001b[39mcast(train_labels, tf\u001b[38;5;241m.\u001b[39mint64))\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Apply preprocessing\u001b[39;00m\n\u001b[1;32m     42\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mmap(preprocess_train, num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:827\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:49\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m     45\u001b[0m   batch_dim\u001b[38;5;241m.\u001b[39massert_is_compatible_with(\n\u001b[1;32m     46\u001b[0m       tensor_shape\u001b[38;5;241m.\u001b[39mDimension(\n\u001b[1;32m     47\u001b[0m           tensor_shape\u001b[38;5;241m.\u001b[39mdimension_value(t\u001b[38;5;241m.\u001b[39mget_shape()[\u001b[38;5;241m0\u001b[39m])))\n\u001b[0;32m---> 49\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_slice_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_tensor_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_structure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(variant_tensor)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:7791\u001b[0m, in \u001b[0;36mtensor_slice_dataset\u001b[0;34m(components, output_shapes, is_files, metadata, replicate_on_split, name)\u001b[0m\n\u001b[1;32m   7789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   7790\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 7791\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7792\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTensorSliceDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7793\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7794\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreplicate_on_split\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplicate_on_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7795\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   7796\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Data parameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Ensure eager execution\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Data preprocessing functions\n",
    "def preprocess_train(image, label):\n",
    "    # Scale to [0,1] and normalize\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    mean = tf.constant([0.4914, 0.4822, 0.4465], shape=(1, 1, 3))\n",
    "    std = tf.constant([0.247, 0.243, 0.261], shape=(1, 1, 3))\n",
    "    image = (image - mean) / std\n",
    "    return image, tf.cast(label, tf.int64)\n",
    "\n",
    "def preprocess_test(image, label):\n",
    "    # Only scale to [0,1] without normalization\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, tf.cast(label, tf.int64)\n",
    "\n",
    "# Load and prepare CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Convert labels to int64\n",
    "train_labels = train_labels.astype(np.int64)\n",
    "test_labels = test_labels.astype(np.int64)\n",
    "\n",
    "# Create TensorFlow datasets with explicit dtype\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.cast(train_images, tf.float32), tf.cast(train_labels, tf.int64))\n",
    ")\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.cast(test_images, tf.float32), tf.cast(test_labels, tf.int64))\n",
    ")\n",
    "\n",
    "# Apply preprocessing\n",
    "train_dataset = train_dataset.map(preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(preprocess_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch and shuffle datasets\n",
    "train_dataset = train_dataset.shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Model definition\n",
    "def create_model():\n",
    "    return tf.keras.Sequential([\n",
    "        # Conv Block 1\n",
    "        tf.keras.layers.Conv2D(32, 3, padding='same', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        \n",
    "        # Conv Block 2\n",
    "        tf.keras.layers.Conv2D(64, 3, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        \n",
    "        # Conv Block 3\n",
    "        tf.keras.layers.Conv2D(128, 3, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        \n",
    "        # Classifier\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')  # Added softmax activation\n",
    "    ])\n",
    "\n",
    "# Create and compile model\n",
    "model = create_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # Removed from_logits=True\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"\\nTest accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Save the entire model\n",
    "model.save('trained_model.h5')\n",
    "\n",
    "# Save weights in PyTorch-style binary format (optional)\n",
    "def save_weights_torch_style(model):\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            np.array(layer.kernel.numpy(), dtype='float32').tofile(f'{layer.name}_kernel.bin')\n",
    "            if layer.bias is not None:\n",
    "                np.array(layer.bias.numpy(), dtype='float32').tofile(f'{layer.name}_bias.bin')\n",
    "        elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            np.array(layer.gamma.numpy(), dtype='float32').tofile(f'{layer.name}_gamma.bin')\n",
    "            np.array(layer.beta.numpy(), dtype='float32').tofile(f'{layer.name}_beta.bin')\n",
    "            np.array(layer.moving_mean.numpy(), dtype='float32').tofile(f'{layer.name}_moving_mean.bin')\n",
    "            np.array(layer.moving_variance.numpy(), dtype='float32').tofile(f'{layer.name}_moving_variance.bin')\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            np.array(layer.kernel.numpy(), dtype='float32').tofile(f'{layer.name}_kernel.bin')\n",
    "            np.array(layer.bias.numpy(), dtype='float32').tofile(f'{layer.name}_bias.bin')\n",
    "\n",
    "save_weights_torch_style(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

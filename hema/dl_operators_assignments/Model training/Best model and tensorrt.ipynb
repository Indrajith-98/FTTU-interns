{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Ensure CUDA and cuDNN are installed\n",
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "\n",
        "# Install the required dependencies for building TensorFlow with TensorRT support\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y libnvinfer8 libnvinfer-dev libnvinfer-plugin8\n",
        "# (Install other necessary packages as mentioned in TensorFlow documentation)\n",
        "\n",
        "# Clone the TensorFlow repository and checkout the desired branch\n",
        "!git clone https://github.com/tensorflow/tensorflow.git\n",
        "%cd tensorflow\n",
        "!git checkout r2.10 # Check the TensorFlow-TensorRT compatibility matrix for the correct branch.\n",
        "\n",
        "# Configure TensorFlow build with TensorRT enabled\n",
        "# ./configure\n",
        "# (During configuration, enable TensorRT support when prompted)\n",
        "# If you are using a virtual environment, activate it before building TensorFlow.\n",
        "\n",
        "# Build and install TensorFlow\n",
        "!bazel build --config=cuda --config=monolithic ... (Specify the build target with TensorRT support)\n",
        "!bazel install ... (Install the built TensorFlow package)\n",
        "\n",
        "# After successful installation, restart the runtime to ensure the new TensorFlow installation is used."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WROQ73Zc_VAd",
        "outputId": "13635c0d-681a-4055-b8f6-8ebd28464087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Mon Dec 23 06:44:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,630 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,517 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,614 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,517 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,564 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,830 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,448 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Fetched 26.9 MB in 3s (10.0 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libnvinfer-headers-dev libnvinfer10\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-dev libnvinfer-headers-dev libnvinfer-plugin8 libnvinfer10\n",
            "  libnvinfer8\n",
            "0 upgraded, 5 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 2,989 MB of archives.\n",
            "After this operation, 7,707 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-headers-dev 10.7.0.23-1+cuda12.6 [106 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer10 10.7.0.23-1+cuda12.6 [1,240 MB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dev 10.7.0.23-1+cuda12.6 [1,246 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer8 8.6.1.6-1+cuda12.0 [492 MB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin8 8.6.1.6-1+cuda12.0 [11.7 MB]\n",
            "Fetched 2,989 MB in 58s (51.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libnvinfer-headers-dev.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../libnvinfer-headers-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-headers-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer10.\n",
            "Preparing to unpack .../libnvinfer10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-dev.\n",
            "Preparing to unpack .../libnvinfer-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer8.\n",
            "Preparing to unpack .../libnvinfer8_8.6.1.6-1+cuda12.0_amd64.deb ...\n",
            "Unpacking libnvinfer8 (8.6.1.6-1+cuda12.0) ...\n",
            "Selecting previously unselected package libnvinfer-plugin8.\n",
            "Preparing to unpack .../libnvinfer-plugin8_8.6.1.6-1+cuda12.0_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin8 (8.6.1.6-1+cuda12.0) ...\n",
            "Setting up libnvinfer-headers-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer8 (8.6.1.6-1+cuda12.0) ...\n",
            "Setting up libnvinfer-plugin8 (8.6.1.6-1+cuda12.0) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Cloning into 'tensorflow'...\n",
            "remote: Enumerating objects: 1937856, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 1937856 (delta 64), reused 1 (delta 1), pack-reused 1937773 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1937856/1937856), 1.05 GiB | 27.62 MiB/s, done.\n",
            "Resolving deltas: 100% (1593328/1593328), done.\n",
            "Updating files: 100% (34426/34426), done.\n",
            "/content/tensorflow\n",
            "Updating files: 100% (27889/27889), done.\n",
            "Branch 'r2.10' set up to track remote branch 'r2.10' from 'origin'.\n",
            "Switched to a new branch 'r2.10'\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `bazel build --config=cuda --config=monolithic ... (Specify the build target with TensorRT support)'\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `bazel install ... (Install the built TensorFlow package)'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J34DDCJAb0OF",
        "outputId": "26e9f9c6-6c0e-487c-c34f-2fb3ef79c5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan  2 10:02:16 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Try importing TensorRT support from TensorFlow\n",
        "    from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "    print(\"TensorFlow TensorRT (TF-TRT) is available.\")\n",
        "except ImportError:\n",
        "    print(\"TensorFlow is not linked with TensorRT.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRT9J1LM3CeQ",
        "outputId": "ceb6672a-06a1-4f9a-d12f-b5dd8b962e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow TensorRT (TF-TRT) is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import datasets, layers, models, Input\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "\n",
        "# Define the CNN model with Dropout\n",
        "def create_model(dropout_rate=0.2):\n",
        "    model = models.Sequential([\n",
        "        Input(shape=(32, 32, 3)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(10, activation='softmax'),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = create_model(dropout_rate=0.2)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * 0.95 ** epoch)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=64,\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_test, y_test),callbacks=[early_stopping,lr_schedule])\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    report = classification_report(y_test, y_pred_classes, target_names=[str(i) for i in range(10)])\n",
        "    accuracy = np.mean(y_pred_classes == y_test)\n",
        "    return report, accuracy\n",
        "\n",
        "report, accuracy = evaluate_model(model, x_test, y_test)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Classification Report:\\n{report}\")\n",
        "\n",
        "# Step 3: Measure latency of the best model\n",
        "def measure_latency(model, x_sample, device):\n",
        "    with tf.device(device):\n",
        "        start_time = time.time()\n",
        "        model.predict(np.expand_dims(x_sample, axis=0))\n",
        "        end_time = time.time()\n",
        "    return end_time - start_time\n",
        "\n",
        "# Measure latency on CPU and GPU\n",
        "print(\"\\n=== Measuring Latency for Best Model ===\")\n",
        "sample_image = x_test[1]\n",
        "try:\n",
        "    cpu_latency = measure_latency(model, sample_image, '/CPU:0')\n",
        "except:\n",
        "    cpu_latency = \"CPU not available\"\n",
        "try:\n",
        "    gpu_latency = measure_latency(model, sample_image, '/GPU:0')\n",
        "except:\n",
        "    gpu_latency = \"GPU not available\"\n",
        "\n",
        "print(f\"Latency on CPU: {cpu_latency}\")\n",
        "print(f\"Latency on GPU: {gpu_latency}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcnV-w4sb2gW",
        "outputId": "2fd943c4-efd8-4ad9-a747-51047b1d8e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Epoch 1/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.3289 - loss: 1.8121 - val_accuracy: 0.5430 - val_loss: 1.2861 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.5558 - loss: 1.2447 - val_accuracy: 0.6044 - val_loss: 1.1046 - learning_rate: 9.5000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.6287 - loss: 1.0522 - val_accuracy: 0.6599 - val_loss: 0.9751 - learning_rate: 9.0250e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.6738 - loss: 0.9268 - val_accuracy: 0.6831 - val_loss: 0.9156 - learning_rate: 8.5737e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7104 - loss: 0.8321 - val_accuracy: 0.7005 - val_loss: 0.8728 - learning_rate: 8.1451e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.7339 - loss: 0.7527 - val_accuracy: 0.6924 - val_loss: 0.8864 - learning_rate: 7.7378e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7577 - loss: 0.7010 - val_accuracy: 0.7241 - val_loss: 0.8016 - learning_rate: 7.3509e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7783 - loss: 0.6341 - val_accuracy: 0.7307 - val_loss: 0.7970 - learning_rate: 6.9834e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7968 - loss: 0.5829 - val_accuracy: 0.7306 - val_loss: 0.7930 - learning_rate: 6.6342e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8066 - loss: 0.5480 - val_accuracy: 0.7349 - val_loss: 0.8082 - learning_rate: 6.3025e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8296 - loss: 0.4844 - val_accuracy: 0.7397 - val_loss: 0.7803 - learning_rate: 5.9874e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8363 - loss: 0.4623 - val_accuracy: 0.7377 - val_loss: 0.8402 - learning_rate: 5.6880e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8537 - loss: 0.4179 - val_accuracy: 0.7479 - val_loss: 0.8081 - learning_rate: 5.4036e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8627 - loss: 0.3900 - val_accuracy: 0.7471 - val_loss: 0.8170 - learning_rate: 5.1334e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8736 - loss: 0.3549 - val_accuracy: 0.7436 - val_loss: 0.8629 - learning_rate: 4.8767e-04\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Model Accuracy: 0.7479\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.77      0.77      1000\n",
            "           1       0.88      0.87      0.87      1000\n",
            "           2       0.69      0.58      0.63      1000\n",
            "           3       0.54      0.62      0.58      1000\n",
            "           4       0.67      0.73      0.70      1000\n",
            "           5       0.71      0.60      0.65      1000\n",
            "           6       0.79      0.83      0.81      1000\n",
            "           7       0.81      0.77      0.79      1000\n",
            "           8       0.80      0.88      0.84      1000\n",
            "           9       0.83      0.83      0.83      1000\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.75      0.75     10000\n",
            "weighted avg       0.75      0.75      0.75     10000\n",
            "\n",
            "\n",
            "=== Measuring Latency for Best Model ===\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step\n",
            "Latency on CPU: CPU not available\n",
            "Latency on GPU: 0.41469478607177734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "\n",
        "# # Save the model\n",
        "# saved_model = '/content/drive/MyDrive/cifar_model_2'\n",
        "# model.export(saved_model)\n",
        "model.save('cifar10_model1.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoWfaClPdBZI",
        "outputId": "91ffd6d0-6846-42bb-e104-0333936681d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define TensorRT conversion\n",
        "trt_model_dir = '/content/drive/MyDrive/trt_model_2'\n",
        "converter = trt.TrtGraphConverterV2(input_saved_model_dir=saved_model)\n",
        "\n",
        "# Convert to TensorRT\n",
        "converter.convert()\n",
        "\n",
        "# Save the converted model\n",
        "converter.save(trt_model_dir)\n",
        "\n",
        "print(f\"TensorRT model saved to {trt_model_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0Pp-Gtq-mAq",
        "outputId": "21b93d23-8d26-438d-e54c-faabcea5c0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorRT model saved to /content/drive/MyDrive/trt_model_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# Path to the saved TensorRT-optimized model\n",
        "saved_model_dir = '/content/drive/MyDrive/trt_model_2'\n",
        "\n",
        "# Load the TensorRT-optimized model\n",
        "trt_model = tf.saved_model.load(saved_model_dir)\n",
        "infer = trt_model.signatures[\"serving_default\"]\n"
      ],
      "metadata": {
        "id": "t1XbUxEcU0Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL6_hfw4QduY",
        "outputId": "475bc491-3aba-42ac-a99f-52010a4d93e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the input data to float32 before inference\n",
        "def evaluate_trt_model(infer, x_test, y_test):\n",
        "    y_pred_classes = []\n",
        "    for img in x_test:\n",
        "        # Perform inference with the correct data type\n",
        "        predictions = infer(tf.convert_to_tensor(np.expand_dims(img, axis=0), dtype=tf.float32))\n",
        "        # print(predictions)\n",
        "        y_pred = tf.argmax(predictions['output_0'], axis=1).numpy()\n",
        "        y_pred_classes.append(y_pred[0])\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = np.mean(np.array(y_pred_classes) == y_test)\n",
        "    report = classification_report(y_test, y_pred_classes, target_names=[str(i) for i in range(10)])\n",
        "    return accuracy, report\n",
        "\n",
        "# Evaluate the model after converting inputs to float32\n",
        "accuracy, report = evaluate_trt_model(infer, x_test, y_test)\n",
        "print(f\"TensorRT Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXttiLILU5oo",
        "outputId": "66f035a6-9232-47c4-cc3e-c62e88ce5cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorRT Model Accuracy: 75.95%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      1000\n",
            "           1       0.83      0.88      0.86      1000\n",
            "           2       0.73      0.58      0.65      1000\n",
            "           3       0.56      0.67      0.61      1000\n",
            "           4       0.70      0.74      0.72      1000\n",
            "           5       0.63      0.72      0.67      1000\n",
            "           6       0.86      0.78      0.82      1000\n",
            "           7       0.84      0.77      0.80      1000\n",
            "           8       0.88      0.82      0.85      1000\n",
            "           9       0.87      0.81      0.84      1000\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.76      0.76     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_latency(infer, inputs, batch_size=1):\n",
        "    \"\"\"\n",
        "    Measures latency for single and batch inference.\n",
        "\n",
        "    Parameters:\n",
        "    - infer: TensorRT-optimized inference function\n",
        "    - inputs: Input data for inference (e.g., test dataset)\n",
        "    - batch_size: Number of images in a batch for batch inference\n",
        "\n",
        "    Returns:\n",
        "    - single_latency: Latency for a single inference (seconds)\n",
        "    - batch_latency: Latency for batch inference (seconds)\n",
        "    \"\"\"\n",
        "    # Single input\n",
        "    single_input = tf.convert_to_tensor(np.expand_dims(inputs[0], axis=0), dtype=tf.float32)\n",
        "\n",
        "    # Single inference latency\n",
        "    start_time = time.time()\n",
        "    infer(single_input)\n",
        "    single_latency = time.time() - start_time\n",
        "\n",
        "    # Batch input\n",
        "    batch_input = tf.convert_to_tensor(inputs[:batch_size], dtype=tf.float32)\n",
        "\n",
        "    # Batch inference latency\n",
        "    start_time = time.time()\n",
        "    infer(batch_input)\n",
        "    batch_latency = time.time() - start_time\n",
        "\n",
        "    return single_latency, batch_latency\n",
        "\n",
        "batch_size = 64\n",
        "single_latency, batch_latency = measure_latency(infer, x_test, batch_size=batch_size)\n",
        "\n",
        "print(f\"Single Inference Latency: {single_latency:.6f} seconds\")\n",
        "print(f\"Batch Inference Latency (batch size={batch_size}): {batch_latency:.6f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbI5MQS1WTjC",
        "outputId": "ab8a65fe-1503-4740-c120-eaf9dfbdd7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Inference Latency: 0.002719 seconds\n",
            "Batch Inference Latency (batch size=64): 12.533403 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('/content/cifar10_model1.h5')  # Replace with your model path\n",
        "\n",
        "# Create dummy input (the shape should match your model's expected input)\n",
        "# Set all input values to 1\n",
        "dummy_input = np.full((1, 32, 32, 3), 1.0, dtype=np.float32)  # Ensure the dtype is float32\n",
        "\n",
        "# Convert the dummy input to a TensorFlow tensor\n",
        "dummy_input = tf.convert_to_tensor(dummy_input)\n",
        "\n",
        "# Print the initial dummy input\n",
        "print(\"Initial Dummy Input:\")\n",
        "print(dummy_input.shape)\n",
        "print(dummy_input.numpy())\n",
        "\n",
        "# Iterate through each layer of the model to get the output at that layer\n",
        "output = dummy_input\n",
        "\n",
        "# Process each layer one by one and print the output at each layer\n",
        "for i, layer in enumerate(model.layers):\n",
        "    output = layer(output)  # Pass the output from the previous layer to the next layer\n",
        "    print(f\"\\nOutput of layer {layer.name}:\")\n",
        "    print(output.shape)\n",
        "    print(output.numpy())  # Use .numpy() to convert tensor to NumPy array for easy printing\n",
        "\n",
        "# Get the final output prediction\n",
        "final_prediction = model(dummy_input)\n",
        "\n",
        "# Print the final prediction\n",
        "print(\"\\nFinal Prediction (class probabilities):\")\n",
        "print(final_prediction.numpy())\n",
        "\n",
        "# Get the predicted class (max probability)\n",
        "predicted_class = tf.argmax(final_prediction, axis=-1).numpy()[0]\n",
        "print(f\"\\nPredicted Class: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xun6c_93jt9Z",
        "outputId": "e1de5447-e881-465e-a169-be1e80744d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Dummy Input:\n",
            "(1, 32, 32, 3)\n",
            "[[[[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]]\n",
            "\n",
            "  [[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]]\n",
            "\n",
            "  [[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]]\n",
            "\n",
            "  [[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]]\n",
            "\n",
            "  [[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]]]]\n",
            "\n",
            "Output of layer conv2d:\n",
            "(1, 30, 30, 128)\n",
            "[[[[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]]]\n",
            "\n",
            "Output of layer max_pooling2d:\n",
            "(1, 15, 15, 128)\n",
            "[[[[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]]]\n",
            "\n",
            "Output of layer conv2d_1:\n",
            "(1, 13, 13, 128)\n",
            "[[[[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]]]\n",
            "\n",
            "Output of layer max_pooling2d_1:\n",
            "(1, 6, 6, 128)\n",
            "[[[[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.04444271 0.         0.         ... 0.         0.\n",
            "    0.        ]]]]\n",
            "\n",
            "Output of layer conv2d_2:\n",
            "(1, 4, 4, 128)\n",
            "[[[[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]]]\n",
            "\n",
            "Output of layer flatten:\n",
            "(1, 2048)\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "Output of layer dense:\n",
            "(1, 128)\n",
            "[[0.         0.02248949 1.3761747  0.         0.2146483  0.\n",
            "  0.         1.896553   0.         0.3300272  0.         0.\n",
            "  0.         0.         0.21627703 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.21854559 0.2761219\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.7525429  0.         0.         0.         0.40715188 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.15111265 0.         0.         0.\n",
            "  0.38165754 0.         0.         0.         0.         0.\n",
            "  0.         0.28493482 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.3421437\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.6122218  1.3174596  1.7243782  0.         0.         0.\n",
            "  0.95851827 0.4880286  0.         0.         0.84903646 0.1684168\n",
            "  0.         0.         0.1086542  0.15489462 0.         0.\n",
            "  0.2538505  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99638486 0.         0.\n",
            "  0.         0.         0.         0.3719915  0.12609416 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.4597946  0.         0.         0.14636514 0.\n",
            "  0.         0.        ]]\n",
            "\n",
            "Output of layer dropout:\n",
            "(1, 128)\n",
            "[[0.         0.02248949 1.3761747  0.         0.2146483  0.\n",
            "  0.         1.896553   0.         0.3300272  0.         0.\n",
            "  0.         0.         0.21627703 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.21854559 0.2761219\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.7525429  0.         0.         0.         0.40715188 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.15111265 0.         0.         0.\n",
            "  0.38165754 0.         0.         0.         0.         0.\n",
            "  0.         0.28493482 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.3421437\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.6122218  1.3174596  1.7243782  0.         0.         0.\n",
            "  0.95851827 0.4880286  0.         0.         0.84903646 0.1684168\n",
            "  0.         0.         0.1086542  0.15489462 0.         0.\n",
            "  0.2538505  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99638486 0.         0.\n",
            "  0.         0.         0.         0.3719915  0.12609416 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.4597946  0.         0.         0.14636514 0.\n",
            "  0.         0.        ]]\n",
            "\n",
            "Output of layer dense_1:\n",
            "(1, 10)\n",
            "[[0.34380373 0.00278927 0.10477856 0.12899995 0.02116346 0.07979523\n",
            "  0.04212849 0.00518647 0.26354977 0.00780508]]\n",
            "\n",
            "Final Prediction (class probabilities):\n",
            "[[0.34380373 0.00278927 0.10477856 0.12899995 0.02116346 0.07979523\n",
            "  0.04212849 0.00518647 0.26354977 0.00780508]]\n",
            "\n",
            "Predicted Class: 0\n"
          ]
        }
      ]
    }
  ]
}